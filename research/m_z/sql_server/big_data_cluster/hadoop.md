# - **[SQL Server Integrates Hadoop and Spark out-of-the box: The Why?](https://www.sqlservercentral.com/articles/sql-server-integrates-hadoop-and-spark-out-of-the-box-the-why)**

Frank A. Banin, 2021-05-14 (first published: 2019-09-09)

## Introduction

Microsoft announced in September 2018 that SQL Server 2019, which is now in preview, will have a Big Data Cluster deployment option. This is a Big-Data-capable SQL Server with elastic scale and extended Artificial Intelligence (AI) capabilities, mostly as a result of deep integration of Hadoop and Spark out-of-the-box.  The new **[SQL Server Big Data Cluster] is expected to yield a lot more than the ability to employ Hadoop and Spark directly from a SQL Server environment. This managed ecosystem particularly presents new approaches to data virtualization that allows one to easily integrate data across multiple data sources without needing to move data by ETL processes. It also enables Modern and Logical Data Warehouses with Polyglot Persistence architecture and designs that employs multiple data storage technologies, for e.g. via a data lake.

In SQL Server, **elastic scale** refers to the ability to automatically and dynamically increase or decrease computing resources (like CPU, memory, and storage) in response to changing workload demands, typically without manual intervention. This is a core concept in cloud computing, especially for services like Azure SQL Database.
