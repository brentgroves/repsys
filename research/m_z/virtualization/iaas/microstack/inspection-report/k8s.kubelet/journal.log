May 16 19:33:14 research21 systemd[1]: Started snap.k8s.kubelet.service - Service for snap application k8s.kubelet.
May 16 19:33:15 research21 k8s.kubelet[37226]: The connection to the server 127.0.0.1:6443 was refused - did you specify the right host or port?
May 16 19:33:15 research21 k8s.kubelet[37018]: Waiting for kube-apiserver to start
May 16 19:33:18 research21 k8s.kubelet[37295]: Error from server (Forbidden): forbidden: User "system:node:research21" cannot get path "/readyz"
May 16 19:33:18 research21 k8s.kubelet[37018]: Waiting for kube-apiserver to start
May 16 19:33:21 research21 k8s.kubelet[37018]: + ulimit -c unlimited
May 16 19:33:21 research21 k8s.kubelet[37018]: + export GOTRACEBACK=crash
May 16 19:33:21 research21 k8s.kubelet[37018]: + GOTRACEBACK=crash
May 16 19:33:21 research21 k8s.kubelet[37018]: + [[ -f /var/snap/k8s/common/args/kubelet-env ]]
May 16 19:33:21 research21 k8s.kubelet[37018]: + exec /snap/k8s/2500/bin/kubelet --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/etc/kubernetes/pki/client-ca.crt --cluster-domain=cluster.local --container-runtime-endpoint=/run/containerd/containerd.sock --containerd=/run/containerd/containerd.sock '--eviction-hard=memory.available<100Mi,nodefs.available<1Gi,imagefs.available<1Gi' --fail-swap-on=false --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=172.24.188.57 --node-labels=node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/worker=,k8sd.io/role=control-plane --read-only-port=0 --register-with-taints= --root-dir=/var/lib/kubelet --serialize-image-pulls=false --tls-cert-file=/etc/kubernetes/pki/kubelet.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_RSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_256_GCM_SHA384 --tls-private-key-file=/etc/kubernetes/pki/kubelet.key
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.050070   37018 resolv_conf.go:34] Using /run/systemd/resolve/resolv.conf for the DNS resolver config
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --anonymous-auth has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --authentication-token-webhook has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --authorization-mode has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --client-ca-file has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --cluster-domain has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --container-runtime-endpoint has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --containerd has been deprecated, This is a cadvisor flag that was mistakenly registered with the Kubelet. Due to legacy concerns, it will follow the standard CLI deprecation timeline before being removed.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --eviction-hard has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --read-only-port has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --register-with-taints has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --serialize-image-pulls has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --tls-cert-file has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --tls-cipher-suites has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: Flag --tls-private-key-file has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.052057   37018 server.go:1170] "Use of insecure cipher detected." cipher="TLS_RSA_WITH_AES_128_GCM_SHA256"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.052082   37018 server.go:1170] "Use of insecure cipher detected." cipher="TLS_RSA_WITH_AES_256_GCM_SHA384"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.086769   37018 server.go:520] "Kubelet version" kubeletVersion="v1.32.2"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.086836   37018 server.go:522] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK="crash"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.096938   37018 dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/client-ca.crt"
May 16 19:33:22 research21 k8s.kubelet[37018]: E0516 19:33:22.141874   37018 log.go:32] "RuntimeConfig from runtime service failed" err="rpc error: code = Unimplemented desc = unknown method RuntimeConfig for service runtime.v1.RuntimeService"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.141988   37018 server.go:1421] "CRI implementation should be updated to support RuntimeConfig when KubeletCgroupDriverFromCRI feature gate has been enabled. Falling back to using cgroupDriver from kubelet config."
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.164961   37018 server.go:772] "--cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.165034   37018 server.go:841] "NoSwap is set due to memorySwapBehavior not specified" memorySwapBehavior="" FailSwapOn=false
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.165219   37018 swap_util.go:115] "Swap is on" /proc/swaps contents=<
May 16 19:33:22 research21 k8s.kubelet[37018]:         Filename                                Type                Size                Used                Priority
May 16 19:33:22 research21 k8s.kubelet[37018]:         /swap.img                               file                8388604                0                -2
May 16 19:33:22 research21 k8s.kubelet[37018]:  >
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.165559   37018 container_manager_linux.go:268] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.165596   37018 container_manager_linux.go:273] "Creating Container Manager object based on Node Config" nodeConfig={"NodeName":"research21","RuntimeCgroupsName":"","SystemCgroupsName":"","KubeletCgroupsName":"","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/","CgroupDriver":"systemd","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[{"Signal":"memory.available","Operator":"LessThan","Value":{"Quantity":"100Mi","Percentage":0},"GracePeriod":0,"MinReclaim":null},{"Signal":"nodefs.available","Operator":"LessThan","Value":{"Quantity":"1Gi","Percentage":0},"GracePeriod":0,"MinReclaim":null},{"Signal":"imagefs.available","Operator":"LessThan","Value":{"Quantity":"1Gi","Percentage":0},"GracePeriod":0,"MinReclaim":null}],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null,"CgroupVersion":2}
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.165979   37018 topology_manager.go:138] "Creating topology manager with none policy"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.166000   37018 container_manager_linux.go:304] "Creating device plugin manager"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.166176   37018 state_mem.go:36] "Initialized new in-memory state store"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.173552   37018 kubelet.go:446] "Attempting to sync node with API server"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.174987   37018 kubelet.go:352] "Adding apiserver pod source"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.175049   37018 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.177500   37018 kuberuntime_manager.go:269] "Container runtime initialized" containerRuntime="containerd" version="v1.6.36" apiVersion="v1"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.178232   37018 kubelet.go:890] "Not starting ClusterTrustBundle informer because we are in static kubelet mode"
May 16 19:33:22 research21 k8s.kubelet[37018]: W0516 19:33:22.178341   37018 probe.go:272] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.193132   37018 watchdog_linux.go:99] "Systemd watchdog is not enabled"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.193236   37018 server.go:1287] "Started kubelet"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.198550   37018 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.199025   37018 ratelimit.go:55] "Setting rate limiting for endpoint" service="podresources" qps=100 burstTokens=10
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.199434   37018 server.go:243] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.199533   37018 server.go:169] "Starting to listen" address="0.0.0.0" port=10250
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.224354   37018 dynamic_serving_content.go:135] "Starting controller" name="kubelet-server-cert-files::/etc/kubernetes/pki/kubelet.crt::/etc/kubernetes/pki/kubelet.key"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.227144   37018 volume_manager.go:297] "Starting Kubelet Volume Manager"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.227184   37018 server.go:479] "Adding debug handlers to kubelet server"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.227642   37018 desired_state_of_world_populator.go:149] "Desired state populator starts to run"
May 16 19:33:22 research21 k8s.kubelet[37018]: E0516 19:33:22.228492   37018 kubelet_node_status.go:467] "Error getting the current node from lister" err="node \"research21\" not found"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.265991   37018 reconciler.go:26] "Reconciler: start to sync state"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.266635   37018 factory.go:221] Registration of the containerd container factory successfully
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.266659   37018 factory.go:221] Registration of the systemd container factory successfully
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.266821   37018 factory.go:219] Registration of the crio container factory failed: Get "http://%2Fvar%2Frun%2Fcrio%2Fcrio.sock/info": dial unix /var/run/crio/crio.sock: connect: no such file or directory
May 16 19:33:22 research21 k8s.kubelet[37018]: E0516 19:33:22.309637   37018 kubelet.go:1561] "Image garbage collection failed once. Stats initialization may not have completed yet" err="invalid capacity 0 on image filesystem"
May 16 19:33:22 research21 k8s.kubelet[37018]: E0516 19:33:22.333141   37018 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"research21\" not found" node="research21"
May 16 19:33:22 research21 k8s.kubelet[37018]: E0516 19:33:22.367401   37018 kubelet_node_status.go:467] "Error getting the current node from lister" err="node \"research21\" not found"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.428741   37018 cpu_manager.go:221] "Starting CPU manager" policy="none"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.428772   37018 cpu_manager.go:222] "Reconciling" reconcilePeriod="10s"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.428891   37018 state_mem.go:36] "Initialized new in-memory state store"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.432223   37018 policy_none.go:49] "None policy: Start"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.432256   37018 memory_manager.go:186] "Starting memorymanager" policy="None"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.432280   37018 state_mem.go:35] "Initializing new in-memory state store"
May 16 19:33:22 research21 k8s.kubelet[37018]: E0516 19:33:22.467875   37018 kubelet_node_status.go:467] "Error getting the current node from lister" err="node \"research21\" not found"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.491357   37018 manager.go:519] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.491628   37018 eviction_manager.go:189] "Eviction manager: starting control loop"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.491661   37018 container_log_manager.go:189] "Initializing container log rotate workers" workers=1 monitorPeriod="10s"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.494283   37018 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
May 16 19:33:22 research21 k8s.kubelet[37018]: E0516 19:33:22.496857   37018 eviction_manager.go:267] "eviction manager: failed to check if we have separate container filesystem. Ignoring." err="no imagefs label for configured runtime"
May 16 19:33:22 research21 k8s.kubelet[37018]: E0516 19:33:22.496948   37018 eviction_manager.go:292] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"research21\" not found"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.590264   37018 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.600704   37018 kubelet_node_status.go:76] "Attempting to register node" node="research21"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.636784   37018 kubelet_node_status.go:79] "Successfully registered node" node="research21"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.665435   37018 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.665694   37018 status_manager.go:227] "Starting to sync pod status with apiserver"
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.667477   37018 watchdog_linux.go:127] "Systemd watchdog is not enabled or the interval is invalid, so health checking will not be started."
May 16 19:33:22 research21 k8s.kubelet[37018]: I0516 19:33:22.667504   37018 kubelet.go:2388] "Starting kubelet main sync loop"
May 16 19:33:22 research21 k8s.kubelet[37018]: E0516 19:33:22.674027   37018 kubelet.go:2412] "Skipping pod synchronization" err="PLEG is not healthy: pleg has yet to be successful"
May 16 19:33:23 research21 k8s.kubelet[37018]: I0516 19:33:23.175931   37018 apiserver.go:52] "Watching apiserver"
May 16 19:33:23 research21 k8s.kubelet[37018]: I0516 19:33:23.266441   37018 desired_state_of_world_populator.go:157] "Finished populating initial desired state of world"
May 16 19:33:26 research21 systemd[1]: Stopping snap.k8s.kubelet.service - Service for snap application k8s.kubelet...
May 16 19:33:26 research21 systemd[1]: snap.k8s.kubelet.service: Deactivated successfully.
May 16 19:33:26 research21 systemd[1]: Stopped snap.k8s.kubelet.service - Service for snap application k8s.kubelet.
May 16 19:33:26 research21 systemd[1]: snap.k8s.kubelet.service: Consumed 2.352s CPU time, 49.7M memory peak, 0B memory swap peak.
May 16 19:33:26 research21 systemd[1]: Started snap.k8s.kubelet.service - Service for snap application k8s.kubelet.
May 16 19:33:26 research21 k8s.kubelet[38157]: + ulimit -c unlimited
May 16 19:33:26 research21 k8s.kubelet[38157]: + export GOTRACEBACK=crash
May 16 19:33:26 research21 k8s.kubelet[38157]: + GOTRACEBACK=crash
May 16 19:33:26 research21 k8s.kubelet[38157]: + [[ -f /var/snap/k8s/common/args/kubelet-env ]]
May 16 19:33:26 research21 k8s.kubelet[38157]: + exec /snap/k8s/2500/bin/kubelet --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/etc/kubernetes/pki/client-ca.crt --cluster-dns=10.152.183.178 --cluster-domain=cluster.local --container-runtime-endpoint=/run/containerd/containerd.sock --containerd=/run/containerd/containerd.sock '--eviction-hard=memory.available<100Mi,nodefs.available<1Gi,imagefs.available<1Gi' --fail-swap-on=false --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=172.24.188.57 --node-labels=node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/worker=,k8sd.io/role=control-plane --read-only-port=0 --register-with-taints= --root-dir=/var/lib/kubelet --serialize-image-pulls=false --tls-cert-file=/etc/kubernetes/pki/kubelet.crt --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_RSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_256_GCM_SHA384 --tls-private-key-file=/etc/kubernetes/pki/kubelet.key
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.089088   38157 resolv_conf.go:34] Using /run/systemd/resolve/resolv.conf for the DNS resolver config
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --anonymous-auth has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --authentication-token-webhook has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --authorization-mode has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --client-ca-file has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --cluster-dns has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --cluster-domain has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --container-runtime-endpoint has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --containerd has been deprecated, This is a cadvisor flag that was mistakenly registered with the Kubelet. Due to legacy concerns, it will follow the standard CLI deprecation timeline before being removed.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --eviction-hard has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --read-only-port has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --register-with-taints has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --serialize-image-pulls has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --tls-cert-file has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --tls-cipher-suites has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: Flag --tls-private-key-file has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.097581   38157 server.go:1170] "Use of insecure cipher detected." cipher="TLS_RSA_WITH_AES_128_GCM_SHA256"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.097621   38157 server.go:1170] "Use of insecure cipher detected." cipher="TLS_RSA_WITH_AES_256_GCM_SHA384"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.119878   38157 server.go:520] "Kubelet version" kubeletVersion="v1.32.2"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.120142   38157 server.go:522] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK="crash"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.135076   38157 dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/client-ca.crt"
May 16 19:33:27 research21 k8s.kubelet[38157]: E0516 19:33:27.147496   38157 log.go:32] "RuntimeConfig from runtime service failed" err="rpc error: code = Unimplemented desc = unknown method RuntimeConfig for service runtime.v1.RuntimeService"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.147847   38157 server.go:1421] "CRI implementation should be updated to support RuntimeConfig when KubeletCgroupDriverFromCRI feature gate has been enabled. Falling back to using cgroupDriver from kubelet config."
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.167819   38157 server.go:772] "--cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.167938   38157 server.go:841] "NoSwap is set due to memorySwapBehavior not specified" memorySwapBehavior="" FailSwapOn=false
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.168168   38157 swap_util.go:115] "Swap is on" /proc/swaps contents=<
May 16 19:33:27 research21 k8s.kubelet[38157]:         Filename                                Type                Size                Used                Priority
May 16 19:33:27 research21 k8s.kubelet[38157]:         /swap.img                               file                8388604                0                -2
May 16 19:33:27 research21 k8s.kubelet[38157]:  >
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.168815   38157 container_manager_linux.go:268] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.168864   38157 container_manager_linux.go:273] "Creating Container Manager object based on Node Config" nodeConfig={"NodeName":"research21","RuntimeCgroupsName":"","SystemCgroupsName":"","KubeletCgroupsName":"","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/","CgroupDriver":"systemd","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[{"Signal":"memory.available","Operator":"LessThan","Value":{"Quantity":"100Mi","Percentage":0},"GracePeriod":0,"MinReclaim":null},{"Signal":"nodefs.available","Operator":"LessThan","Value":{"Quantity":"1Gi","Percentage":0},"GracePeriod":0,"MinReclaim":null},{"Signal":"imagefs.available","Operator":"LessThan","Value":{"Quantity":"1Gi","Percentage":0},"GracePeriod":0,"MinReclaim":null}],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null,"CgroupVersion":2}
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.169228   38157 topology_manager.go:138] "Creating topology manager with none policy"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.169250   38157 container_manager_linux.go:304] "Creating device plugin manager"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.169345   38157 state_mem.go:36] "Initialized new in-memory state store"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.171278   38157 kubelet.go:446] "Attempting to sync node with API server"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.171501   38157 kubelet.go:352] "Adding apiserver pod source"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.171642   38157 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.174958   38157 kuberuntime_manager.go:269] "Container runtime initialized" containerRuntime="containerd" version="v1.6.36" apiVersion="v1"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.175715   38157 kubelet.go:890] "Not starting ClusterTrustBundle informer because we are in static kubelet mode"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.180111   38157 watchdog_linux.go:99] "Systemd watchdog is not enabled"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.180174   38157 server.go:1287] "Started kubelet"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.183032   38157 server.go:169] "Starting to listen" address="0.0.0.0" port=10250
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.185757   38157 ratelimit.go:55] "Setting rate limiting for endpoint" service="podresources" qps=100 burstTokens=10
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.192543   38157 server.go:243] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.202222   38157 server.go:479] "Adding debug handlers to kubelet server"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.215682   38157 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
May 16 19:33:27 research21 k8s.kubelet[38157]: E0516 19:33:27.237571   38157 kubelet_node_status.go:467] "Error getting the current node from lister" err="node \"research21\" not found"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.240649   38157 dynamic_serving_content.go:135] "Starting controller" name="kubelet-server-cert-files::/etc/kubernetes/pki/kubelet.crt::/etc/kubernetes/pki/kubelet.key"
May 16 19:33:27 research21 k8s.kubelet[38157]: E0516 19:33:27.245769   38157 kubelet.go:1561] "Image garbage collection failed once. Stats initialization may not have completed yet" err="invalid capacity 0 on image filesystem"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.255769   38157 factory.go:219] Registration of the crio container factory failed: Get "http://%2Fvar%2Frun%2Fcrio%2Fcrio.sock/info": dial unix /var/run/crio/crio.sock: connect: no such file or directory
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.259045   38157 volume_manager.go:297] "Starting Kubelet Volume Manager"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.259211   38157 desired_state_of_world_populator.go:149] "Desired state populator starts to run"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.259309   38157 reconciler.go:26] "Reconciler: start to sync state"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.266506   38157 factory.go:221] Registration of the containerd container factory successfully
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.266541   38157 factory.go:221] Registration of the systemd container factory successfully
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.338492   38157 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.347150   38157 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.347222   38157 status_manager.go:227] "Starting to sync pod status with apiserver"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.347291   38157 watchdog_linux.go:127] "Systemd watchdog is not enabled or the interval is invalid, so health checking will not be started."
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.347306   38157 kubelet.go:2388] "Starting kubelet main sync loop"
May 16 19:33:27 research21 k8s.kubelet[38157]: E0516 19:33:27.347388   38157 kubelet.go:2412] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.444939   38157 cpu_manager.go:221] "Starting CPU manager" policy="none"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.444962   38157 cpu_manager.go:222] "Reconciling" reconcilePeriod="10s"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.444996   38157 state_mem.go:36] "Initialized new in-memory state store"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.447032   38157 state_mem.go:88] "Updated default CPUSet" cpuSet=""
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.447064   38157 state_mem.go:96] "Updated CPUSet assignments" assignments={}
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.447100   38157 policy_none.go:49] "None policy: Start"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.447126   38157 memory_manager.go:186] "Starting memorymanager" policy="None"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.447151   38157 state_mem.go:35] "Initializing new in-memory state store"
May 16 19:33:27 research21 k8s.kubelet[38157]: E0516 19:33:27.447872   38157 kubelet.go:2412] "Skipping pod synchronization" err="container runtime status check may not have completed yet"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.449378   38157 state_mem.go:75] "Updated machine memory state"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.463865   38157 manager.go:519] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.467256   38157 eviction_manager.go:189] "Eviction manager: starting control loop"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.467287   38157 container_log_manager.go:189] "Initializing container log rotate workers" workers=1 monitorPeriod="10s"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.467880   38157 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
May 16 19:33:27 research21 k8s.kubelet[38157]: E0516 19:33:27.473352   38157 eviction_manager.go:267] "eviction manager: failed to check if we have separate container filesystem. Ignoring." err="no imagefs label for configured runtime"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.585784   38157 kubelet_node_status.go:76] "Attempting to register node" node="research21"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.612087   38157 kubelet_node_status.go:125] "Node was previously registered" node="research21"
May 16 19:33:27 research21 k8s.kubelet[38157]: I0516 19:33:27.612233   38157 kubelet_node_status.go:79] "Successfully registered node" node="research21"
May 16 19:33:28 research21 k8s.kubelet[38157]: I0516 19:33:28.173034   38157 apiserver.go:52] "Watching apiserver"
May 16 19:33:28 research21 k8s.kubelet[38157]: I0516 19:33:28.259697   38157 desired_state_of_world_populator.go:157] "Finished populating initial desired state of world"
May 16 19:33:31 research21 k8s.kubelet[38157]: E0516 19:33:31.954650   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092392   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"registration-dir\" (UniqueName: \"kubernetes.io/host-path/478e2f54-5815-4945-accc-2453884e1a31-registration-dir\") pod \"ck-storage-rawfile-csi-node-z9lvt\" (UID: \"478e2f54-5815-4945-accc-2453884e1a31\") " pod="kube-system/ck-storage-rawfile-csi-node-z9lvt"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092477   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"hostproc\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-hostproc\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092524   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-xtables-lock\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092567   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"host-proc-sys-net\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-host-proc-sys-net\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092605   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"host-proc-sys-kernel\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-host-proc-sys-kernel\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092640   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"hubble-tls\" (UniqueName: \"kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-hubble-tls\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092674   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-4kdjq\" (UniqueName: \"kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-kube-api-access-4kdjq\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092710   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp\" (UniqueName: \"kubernetes.io/empty-dir/4c36c8ca-e2a9-403c-9602-bd18429db717-tmp\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092757   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-lib-modules\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092794   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-6xcpl\" (UniqueName: \"kubernetes.io/projected/478e2f54-5815-4945-accc-2453884e1a31-kube-api-access-6xcpl\") pod \"ck-storage-rawfile-csi-node-z9lvt\" (UID: \"478e2f54-5815-4945-accc-2453884e1a31\") " pod="kube-system/ck-storage-rawfile-csi-node-z9lvt"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092829   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-run\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-run\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092864   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-netns\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-netns\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092903   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"bpf-maps\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-bpf-maps\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092941   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-cgroup\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-cgroup\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.092975   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-cni-netd\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-etc-cni-netd\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.093009   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"mountpoint-dir\" (UniqueName: \"kubernetes.io/host-path/478e2f54-5815-4945-accc-2453884e1a31-mountpoint-dir\") pod \"ck-storage-rawfile-csi-node-z9lvt\" (UID: \"478e2f54-5815-4945-accc-2453884e1a31\") " pod="kube-system/ck-storage-rawfile-csi-node-z9lvt"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.093046   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-path\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cni-path\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.093083   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"clustermesh-secrets\" (UniqueName: \"kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-clustermesh-secrets\") pod \"cilium-lhphd\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") " pod="kube-system/cilium-lhphd"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.093119   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"socket-dir\" (UniqueName: \"kubernetes.io/host-path/478e2f54-5815-4945-accc-2453884e1a31-socket-dir\") pod \"ck-storage-rawfile-csi-node-z9lvt\" (UID: \"478e2f54-5815-4945-accc-2453884e1a31\") " pod="kube-system/ck-storage-rawfile-csi-node-z9lvt"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.093162   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"data-dir\" (UniqueName: \"kubernetes.io/host-path/478e2f54-5815-4945-accc-2453884e1a31-data-dir\") pod \"ck-storage-rawfile-csi-node-z9lvt\" (UID: \"478e2f54-5815-4945-accc-2453884e1a31\") " pod="kube-system/ck-storage-rawfile-csi-node-z9lvt"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.397742   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-hffcj\" (UniqueName: \"kubernetes.io/projected/e0d83fa0-5e3b-4c70-b91d-e6491c41322c-kube-api-access-hffcj\") pod \"cilium-operator-6978488575-fzsj2\" (UID: \"e0d83fa0-5e3b-4c70-b91d-e6491c41322c\") " pod="kube-system/cilium-operator-6978488575-fzsj2"
May 16 19:33:32 research21 k8s.kubelet[38157]: I0516 19:33:32.398246   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-config-path\" (UniqueName: \"kubernetes.io/configmap/e0d83fa0-5e3b-4c70-b91d-e6491c41322c-cilium-config-path\") pod \"cilium-operator-6978488575-fzsj2\" (UID: \"e0d83fa0-5e3b-4c70-b91d-e6491c41322c\") " pod="kube-system/cilium-operator-6978488575-fzsj2"
May 16 19:33:33 research21 k8s.kubelet[38157]: E0516 19:33:33.348784   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:35 research21 k8s.kubelet[38157]: E0516 19:33:35.347941   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:37 research21 k8s.kubelet[38157]: E0516 19:33:37.349857   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:39 research21 k8s.kubelet[38157]: E0516 19:33:39.354848   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:41 research21 k8s.kubelet[38157]: E0516 19:33:41.356197   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:43 research21 k8s.kubelet[38157]: E0516 19:33:43.351943   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:45 research21 k8s.kubelet[38157]: E0516 19:33:45.351439   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:47 research21 k8s.kubelet[38157]: E0516 19:33:47.348245   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:49 research21 k8s.kubelet[38157]: E0516 19:33:49.348072   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:51 research21 k8s.kubelet[38157]: E0516 19:33:51.358252   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:53 research21 k8s.kubelet[38157]: E0516 19:33:53.353806   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:53 research21 k8s.kubelet[38157]: I0516 19:33:53.599442   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/cilium-operator-6978488575-fzsj2" podStartSLOduration=5.417097091 podStartE2EDuration="21.599416158s" podCreationTimestamp="2025-05-16 19:33:32 -0400 EDT" firstStartedPulling="2025-05-16 19:33:35.276105126 -0400 EDT m=+8.413701811" lastFinishedPulling="2025-05-16 19:33:51.458424193 -0400 EDT m=+24.596020878" observedRunningTime="2025-05-16 19:33:52.560786127 -0400 EDT m=+25.698382821" watchObservedRunningTime="2025-05-16 19:33:53.599416158 -0400 EDT m=+26.737012852"
May 16 19:33:55 research21 k8s.kubelet[38157]: E0516 19:33:55.360966   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:57 research21 k8s.kubelet[38157]: E0516 19:33:57.350045   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:33:59 research21 k8s.kubelet[38157]: E0516 19:33:59.349825   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:01 research21 k8s.kubelet[38157]: E0516 19:34:01.352820   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:03 research21 k8s.kubelet[38157]: E0516 19:34:03.355524   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:05 research21 k8s.kubelet[38157]: E0516 19:34:05.349600   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:07 research21 k8s.kubelet[38157]: E0516 19:34:07.353638   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:09 research21 k8s.kubelet[38157]: E0516 19:34:09.352532   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:11 research21 k8s.kubelet[38157]: E0516 19:34:11.351871   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:13 research21 k8s.kubelet[38157]: E0516 19:34:13.368296   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:15 research21 k8s.kubelet[38157]: E0516 19:34:15.350907   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:17 research21 k8s.kubelet[38157]: E0516 19:34:17.352967   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:19 research21 k8s.kubelet[38157]: E0516 19:34:19.348130   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:21 research21 k8s.kubelet[38157]: E0516 19:34:21.350793   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:23 research21 k8s.kubelet[38157]: E0516 19:34:23.348365   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:25 research21 k8s.kubelet[38157]: E0516 19:34:25.348809   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:27 research21 k8s.kubelet[38157]: E0516 19:34:27.353123   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:29 research21 k8s.kubelet[38157]: E0516 19:34:29.347901   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.221307   38157 memory_manager.go:355] "RemoveStaleState removing state" podUID="e0d83fa0-5e3b-4c70-b91d-e6491c41322c" containerName="cilium-operator"
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.273271   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-hffcj\" (UniqueName: \"kubernetes.io/projected/e0d83fa0-5e3b-4c70-b91d-e6491c41322c-kube-api-access-hffcj\") pod \"e0d83fa0-5e3b-4c70-b91d-e6491c41322c\" (UID: \"e0d83fa0-5e3b-4c70-b91d-e6491c41322c\") "
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.273352   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"cilium-config-path\" (UniqueName: \"kubernetes.io/configmap/e0d83fa0-5e3b-4c70-b91d-e6491c41322c-cilium-config-path\") pod \"e0d83fa0-5e3b-4c70-b91d-e6491c41322c\" (UID: \"e0d83fa0-5e3b-4c70-b91d-e6491c41322c\") "
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.273475   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-s54kc\" (UniqueName: \"kubernetes.io/projected/cb44cab7-bf54-41e1-b09e-943f2fa4a677-kube-api-access-s54kc\") pod \"cilium-operator-6f799b7b4-b4v8x\" (UID: \"cb44cab7-bf54-41e1-b09e-943f2fa4a677\") " pod="kube-system/cilium-operator-6f799b7b4-b4v8x"
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.273534   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-config-path\" (UniqueName: \"kubernetes.io/configmap/cb44cab7-bf54-41e1-b09e-943f2fa4a677-cilium-config-path\") pod \"cilium-operator-6f799b7b4-b4v8x\" (UID: \"cb44cab7-bf54-41e1-b09e-943f2fa4a677\") " pod="kube-system/cilium-operator-6f799b7b4-b4v8x"
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.288416   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/e0d83fa0-5e3b-4c70-b91d-e6491c41322c-kube-api-access-hffcj" (OuterVolumeSpecName: "kube-api-access-hffcj") pod "e0d83fa0-5e3b-4c70-b91d-e6491c41322c" (UID: "e0d83fa0-5e3b-4c70-b91d-e6491c41322c"). InnerVolumeSpecName "kube-api-access-hffcj". PluginName "kubernetes.io/projected", VolumeGIDValue ""
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.319128   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/e0d83fa0-5e3b-4c70-b91d-e6491c41322c-cilium-config-path" (OuterVolumeSpecName: "cilium-config-path") pod "e0d83fa0-5e3b-4c70-b91d-e6491c41322c" (UID: "e0d83fa0-5e3b-4c70-b91d-e6491c41322c"). InnerVolumeSpecName "cilium-config-path". PluginName "kubernetes.io/configmap", VolumeGIDValue ""
May 16 19:34:31 research21 k8s.kubelet[38157]: E0516 19:34:31.353139   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.376674   38157 reconciler_common.go:299] "Volume detached for volume \"kube-api-access-hffcj\" (UniqueName: \"kubernetes.io/projected/e0d83fa0-5e3b-4c70-b91d-e6491c41322c-kube-api-access-hffcj\") on node \"research21\" DevicePath \"\""
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.376723   38157 reconciler_common.go:299] "Volume detached for volume \"cilium-config-path\" (UniqueName: \"kubernetes.io/configmap/e0d83fa0-5e3b-4c70-b91d-e6491c41322c-cilium-config-path\") on node \"research21\" DevicePath \"\""
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.714261   38157 scope.go:117] "RemoveContainer" containerID="44c63b0f7e84806afdda83f59689acf7464df303655026d3de3060a165b7feda"
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.774726   38157 scope.go:117] "RemoveContainer" containerID="44c63b0f7e84806afdda83f59689acf7464df303655026d3de3060a165b7feda"
May 16 19:34:31 research21 k8s.kubelet[38157]: E0516 19:34:31.776855   38157 log.go:32] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"44c63b0f7e84806afdda83f59689acf7464df303655026d3de3060a165b7feda\": not found" containerID="44c63b0f7e84806afdda83f59689acf7464df303655026d3de3060a165b7feda"
May 16 19:34:31 research21 k8s.kubelet[38157]: I0516 19:34:31.776912   38157 pod_container_deletor.go:53] "DeleteContainer returned error" containerID={"Type":"containerd","ID":"44c63b0f7e84806afdda83f59689acf7464df303655026d3de3060a165b7feda"} err="failed to get container status \"44c63b0f7e84806afdda83f59689acf7464df303655026d3de3060a165b7feda\": rpc error: code = NotFound desc = an error occurred when try to find container \"44c63b0f7e84806afdda83f59689acf7464df303655026d3de3060a165b7feda\": not found"
May 16 19:34:33 research21 k8s.kubelet[38157]: E0516 19:34:33.351328   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:33 research21 k8s.kubelet[38157]: I0516 19:34:33.389135   38157 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="e0d83fa0-5e3b-4c70-b91d-e6491c41322c" path="/var/lib/kubelet/pods/e0d83fa0-5e3b-4c70-b91d-e6491c41322c/volumes"
May 16 19:34:33 research21 k8s.kubelet[38157]: I0516 19:34:33.780242   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/cilium-operator-6f799b7b4-b4v8x" podStartSLOduration=5.780217394 podStartE2EDuration="5.780217394s" podCreationTimestamp="2025-05-16 19:34:28 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-05-16 19:34:32.82368744 -0400 EDT m=+65.961284125" watchObservedRunningTime="2025-05-16 19:34:33.780217394 -0400 EDT m=+66.917814086"
May 16 19:34:35 research21 k8s.kubelet[38157]: E0516 19:34:35.355317   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:37 research21 k8s.kubelet[38157]: E0516 19:34:37.349492   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:39 research21 k8s.kubelet[38157]: E0516 19:34:39.352812   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:41 research21 k8s.kubelet[38157]: E0516 19:34:41.348318   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083132   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"cni-path\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cni-path\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083204   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"hostproc\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-hostproc\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083241   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-xtables-lock\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083282   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"tmp\" (UniqueName: \"kubernetes.io/empty-dir/4c36c8ca-e2a9-403c-9602-bd18429db717-tmp\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083285   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cni-path" (OuterVolumeSpecName: "cni-path") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "cni-path". PluginName "kubernetes.io/host-path", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083319   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"cilium-cgroup\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-cgroup\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083352   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"bpf-maps\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-bpf-maps\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083372   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-xtables-lock" (OuterVolumeSpecName: "xtables-lock") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "xtables-lock". PluginName "kubernetes.io/host-path", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083383   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"etc-cni-netd\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-etc-cni-netd\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083418   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-etc-cni-netd" (OuterVolumeSpecName: "etc-cni-netd") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "etc-cni-netd". PluginName "kubernetes.io/host-path", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083450   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"cilium-run\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-run\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083506   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"cilium-netns\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-netns\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083547   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"host-proc-sys-net\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-host-proc-sys-net\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083545   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-hostproc" (OuterVolumeSpecName: "hostproc") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "hostproc". PluginName "kubernetes.io/host-path", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083590   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"hubble-tls\" (UniqueName: \"kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-hubble-tls\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083605   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-netns" (OuterVolumeSpecName: "cilium-netns") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "cilium-netns". PluginName "kubernetes.io/host-path", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083627   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-4kdjq\" (UniqueName: \"kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-kube-api-access-4kdjq\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083658   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-lib-modules\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083694   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"clustermesh-secrets\" (UniqueName: \"kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-clustermesh-secrets\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083728   38157 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"host-proc-sys-kernel\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-host-proc-sys-kernel\") pod \"4c36c8ca-e2a9-403c-9602-bd18429db717\" (UID: \"4c36c8ca-e2a9-403c-9602-bd18429db717\") "
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083780   38157 reconciler_common.go:299] "Volume detached for volume \"etc-cni-netd\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-etc-cni-netd\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083804   38157 reconciler_common.go:299] "Volume detached for volume \"cilium-netns\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-netns\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083828   38157 reconciler_common.go:299] "Volume detached for volume \"cni-path\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cni-path\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083847   38157 reconciler_common.go:299] "Volume detached for volume \"hostproc\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-hostproc\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083866   38157 reconciler_common.go:299] "Volume detached for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-xtables-lock\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083644   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-run" (OuterVolumeSpecName: "cilium-run") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "cilium-run". PluginName "kubernetes.io/host-path", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083685   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-cgroup" (OuterVolumeSpecName: "cilium-cgroup") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "cilium-cgroup". PluginName "kubernetes.io/host-path", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083903   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-host-proc-sys-kernel" (OuterVolumeSpecName: "host-proc-sys-kernel") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "host-proc-sys-kernel". PluginName "kubernetes.io/host-path", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.083930   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-lib-modules" (OuterVolumeSpecName: "lib-modules") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "lib-modules". PluginName "kubernetes.io/host-path", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.084426   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-bpf-maps" (OuterVolumeSpecName: "bpf-maps") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "bpf-maps". PluginName "kubernetes.io/host-path", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.084508   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-host-proc-sys-net" (OuterVolumeSpecName: "host-proc-sys-net") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "host-proc-sys-net". PluginName "kubernetes.io/host-path", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.101535   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/empty-dir/4c36c8ca-e2a9-403c-9602-bd18429db717-tmp" (OuterVolumeSpecName: "tmp") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "tmp". PluginName "kubernetes.io/empty-dir", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.107101   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-clustermesh-secrets" (OuterVolumeSpecName: "clustermesh-secrets") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "clustermesh-secrets". PluginName "kubernetes.io/projected", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.110953   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-kube-api-access-4kdjq" (OuterVolumeSpecName: "kube-api-access-4kdjq") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "kube-api-access-4kdjq". PluginName "kubernetes.io/projected", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.114398   38157 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-hubble-tls" (OuterVolumeSpecName: "hubble-tls") pod "4c36c8ca-e2a9-403c-9602-bd18429db717" (UID: "4c36c8ca-e2a9-403c-9602-bd18429db717"). InnerVolumeSpecName "hubble-tls". PluginName "kubernetes.io/projected", VolumeGIDValue ""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.184393   38157 reconciler_common.go:299] "Volume detached for volume \"bpf-maps\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-bpf-maps\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.184442   38157 reconciler_common.go:299] "Volume detached for volume \"cilium-run\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-run\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.184481   38157 reconciler_common.go:299] "Volume detached for volume \"host-proc-sys-net\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-host-proc-sys-net\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.184502   38157 reconciler_common.go:299] "Volume detached for volume \"hubble-tls\" (UniqueName: \"kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-hubble-tls\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.184521   38157 reconciler_common.go:299] "Volume detached for volume \"kube-api-access-4kdjq\" (UniqueName: \"kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-kube-api-access-4kdjq\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.184539   38157 reconciler_common.go:299] "Volume detached for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-lib-modules\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.184559   38157 reconciler_common.go:299] "Volume detached for volume \"clustermesh-secrets\" (UniqueName: \"kubernetes.io/projected/4c36c8ca-e2a9-403c-9602-bd18429db717-clustermesh-secrets\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.184577   38157 reconciler_common.go:299] "Volume detached for volume \"host-proc-sys-kernel\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-host-proc-sys-kernel\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.184596   38157 reconciler_common.go:299] "Volume detached for volume \"tmp\" (UniqueName: \"kubernetes.io/empty-dir/4c36c8ca-e2a9-403c-9602-bd18429db717-tmp\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.184613   38157 reconciler_common.go:299] "Volume detached for volume \"cilium-cgroup\" (UniqueName: \"kubernetes.io/host-path/4c36c8ca-e2a9-403c-9602-bd18429db717-cilium-cgroup\") on node \"research21\" DevicePath \"\""
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.819922   38157 scope.go:117] "RemoveContainer" containerID="ce218062c0efd9c7fbd5b314c281b8d5fdbfce063e647e70043f81c730cfc30e"
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.964594   38157 memory_manager.go:355] "RemoveStaleState removing state" podUID="4c36c8ca-e2a9-403c-9602-bd18429db717" containerName="config"
May 16 19:34:42 research21 k8s.kubelet[38157]: W0516 19:34:42.978986   38157 reflector.go:569] object-"kube-system"/"clustermesh-apiserver-local-cert": failed to list *v1.Secret: secrets "clustermesh-apiserver-local-cert" is forbidden: User "system:node:research21" cannot list resource "secrets" in API group "" in the namespace "kube-system": no relationship found between node 'research21' and this object
May 16 19:34:42 research21 k8s.kubelet[38157]: W0516 19:34:42.979017   38157 reflector.go:569] object-"kube-system"/"cilium-clustermesh": failed to list *v1.Secret: secrets "cilium-clustermesh" is forbidden: User "system:node:research21" cannot list resource "secrets" in API group "" in the namespace "kube-system": no relationship found between node 'research21' and this object
May 16 19:34:42 research21 k8s.kubelet[38157]: E0516 19:34:42.979057   38157 reflector.go:166] "Unhandled Error" err="object-\"kube-system\"/\"clustermesh-apiserver-local-cert\": Failed to watch *v1.Secret: failed to list *v1.Secret: secrets \"clustermesh-apiserver-local-cert\" is forbidden: User \"system:node:research21\" cannot list resource \"secrets\" in API group \"\" in the namespace \"kube-system\": no relationship found between node 'research21' and this object" logger="UnhandledError"
May 16 19:34:42 research21 k8s.kubelet[38157]: E0516 19:34:42.979065   38157 reflector.go:166] "Unhandled Error" err="object-\"kube-system\"/\"cilium-clustermesh\": Failed to watch *v1.Secret: failed to list *v1.Secret: secrets \"cilium-clustermesh\" is forbidden: User \"system:node:research21\" cannot list resource \"secrets\" in API group \"\" in the namespace \"kube-system\": no relationship found between node 'research21' and this object" logger="UnhandledError"
May 16 19:34:42 research21 k8s.kubelet[38157]: W0516 19:34:42.979200   38157 reflector.go:569] object-"kube-system"/"clustermesh-apiserver-remote-cert": failed to list *v1.Secret: secrets "clustermesh-apiserver-remote-cert" is forbidden: User "system:node:research21" cannot list resource "secrets" in API group "" in the namespace "kube-system": no relationship found between node 'research21' and this object
May 16 19:34:42 research21 k8s.kubelet[38157]: W0516 19:34:42.979231   38157 reflector.go:569] object-"kube-system"/"hubble-server-certs": failed to list *v1.Secret: secrets "hubble-server-certs" is forbidden: User "system:node:research21" cannot list resource "secrets" in API group "" in the namespace "kube-system": no relationship found between node 'research21' and this object
May 16 19:34:42 research21 k8s.kubelet[38157]: E0516 19:34:42.979237   38157 reflector.go:166] "Unhandled Error" err="object-\"kube-system\"/\"clustermesh-apiserver-remote-cert\": Failed to watch *v1.Secret: failed to list *v1.Secret: secrets \"clustermesh-apiserver-remote-cert\" is forbidden: User \"system:node:research21\" cannot list resource \"secrets\" in API group \"\" in the namespace \"kube-system\": no relationship found between node 'research21' and this object" logger="UnhandledError"
May 16 19:34:42 research21 k8s.kubelet[38157]: E0516 19:34:42.979264   38157 reflector.go:166] "Unhandled Error" err="object-\"kube-system\"/\"hubble-server-certs\": Failed to watch *v1.Secret: failed to list *v1.Secret: secrets \"hubble-server-certs\" is forbidden: User \"system:node:research21\" cannot list resource \"secrets\" in API group \"\" in the namespace \"kube-system\": no relationship found between node 'research21' and this object" logger="UnhandledError"
May 16 19:34:42 research21 k8s.kubelet[38157]: I0516 19:34:42.979302   38157 status_manager.go:890] "Failed to get status for pod" podUID="d3fe5374-0783-41b1-b28e-513ad99edfb5" pod="kube-system/cilium-vzx55" err="pods \"cilium-vzx55\" is forbidden: User \"system:node:research21\" cannot get resource \"pods\" in API group \"\" in the namespace \"kube-system\": no relationship found between node 'research21' and this object"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094340   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-netns\" (UniqueName: \"kubernetes.io/host-path/d3fe5374-0783-41b1-b28e-513ad99edfb5-cilium-netns\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094417   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp\" (UniqueName: \"kubernetes.io/empty-dir/d3fe5374-0783-41b1-b28e-513ad99edfb5-tmp\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094470   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-cgroup\" (UniqueName: \"kubernetes.io/host-path/d3fe5374-0783-41b1-b28e-513ad99edfb5-cilium-cgroup\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094516   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"clustermesh-secrets\" (UniqueName: \"kubernetes.io/projected/d3fe5374-0783-41b1-b28e-513ad99edfb5-clustermesh-secrets\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094557   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"host-proc-sys-kernel\" (UniqueName: \"kubernetes.io/host-path/d3fe5374-0783-41b1-b28e-513ad99edfb5-host-proc-sys-kernel\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094591   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"bpf-maps\" (UniqueName: \"kubernetes.io/host-path/d3fe5374-0783-41b1-b28e-513ad99edfb5-bpf-maps\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094625   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-path\" (UniqueName: \"kubernetes.io/host-path/d3fe5374-0783-41b1-b28e-513ad99edfb5-cni-path\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094670   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-cni-netd\" (UniqueName: \"kubernetes.io/host-path/d3fe5374-0783-41b1-b28e-513ad99edfb5-etc-cni-netd\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094705   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/d3fe5374-0783-41b1-b28e-513ad99edfb5-lib-modules\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094738   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"hubble-tls\" (UniqueName: \"kubernetes.io/projected/d3fe5374-0783-41b1-b28e-513ad99edfb5-hubble-tls\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094777   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-bwc4s\" (UniqueName: \"kubernetes.io/projected/d3fe5374-0783-41b1-b28e-513ad99edfb5-kube-api-access-bwc4s\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094820   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cilium-run\" (UniqueName: \"kubernetes.io/host-path/d3fe5374-0783-41b1-b28e-513ad99edfb5-cilium-run\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094855   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"hostproc\" (UniqueName: \"kubernetes.io/host-path/d3fe5374-0783-41b1-b28e-513ad99edfb5-hostproc\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094893   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/d3fe5374-0783-41b1-b28e-513ad99edfb5-xtables-lock\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.094928   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"host-proc-sys-net\" (UniqueName: \"kubernetes.io/host-path/d3fe5374-0783-41b1-b28e-513ad99edfb5-host-proc-sys-net\") pod \"cilium-vzx55\" (UID: \"d3fe5374-0783-41b1-b28e-513ad99edfb5\") " pod="kube-system/cilium-vzx55"
May 16 19:34:43 research21 k8s.kubelet[38157]: I0516 19:34:43.353502   38157 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="4c36c8ca-e2a9-403c-9602-bd18429db717" path="/var/lib/kubelet/pods/4c36c8ca-e2a9-403c-9602-bd18429db717/volumes"
May 16 19:34:43 research21 k8s.kubelet[38157]: E0516 19:34:43.355834   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:44 research21 k8s.kubelet[38157]: E0516 19:34:44.196772   38157 projected.go:263] Couldn't get secret kube-system/cilium-clustermesh: failed to sync secret cache: timed out waiting for the condition
May 16 19:34:44 research21 k8s.kubelet[38157]: E0516 19:34:44.196837   38157 projected.go:194] Error preparing data for projected volume clustermesh-secrets for pod kube-system/cilium-vzx55: failed to sync secret cache: timed out waiting for the condition
May 16 19:34:44 research21 k8s.kubelet[38157]: E0516 19:34:44.196961   38157 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/projected/d3fe5374-0783-41b1-b28e-513ad99edfb5-clustermesh-secrets podName:d3fe5374-0783-41b1-b28e-513ad99edfb5 nodeName:}" failed. No retries permitted until 2025-05-16 19:34:44.69692095 -0400 EDT m=+77.834517637 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "clustermesh-secrets" (UniqueName: "kubernetes.io/projected/d3fe5374-0783-41b1-b28e-513ad99edfb5-clustermesh-secrets") pod "cilium-vzx55" (UID: "d3fe5374-0783-41b1-b28e-513ad99edfb5") : failed to sync secret cache: timed out waiting for the condition
May 16 19:34:45 research21 k8s.kubelet[38157]: E0516 19:34:45.352797   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:47 research21 k8s.kubelet[38157]: E0516 19:34:47.348226   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:49 research21 k8s.kubelet[38157]: E0516 19:34:49.348487   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:50 research21 k8s.kubelet[38157]: I0516 19:34:50.889128   38157 kubelet_resources.go:45] "Allocatable" allocatable={"cpu":"4","ephemeral-storage":"477464304Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"32721880Ki","pods":"110"}
May 16 19:34:51 research21 k8s.kubelet[38157]: E0516 19:34:51.350839   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:51 research21 k8s.kubelet[38157]: I0516 19:34:51.955885   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/cilium-vzx55" podStartSLOduration=9.955855514 podStartE2EDuration="9.955855514s" podCreationTimestamp="2025-05-16 19:34:42 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-05-16 19:34:51.94638942 -0400 EDT m=+85.083986125" watchObservedRunningTime="2025-05-16 19:34:51.955855514 -0400 EDT m=+85.093452198"
May 16 19:34:53 research21 k8s.kubelet[38157]: E0516 19:34:53.351762   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:55 research21 k8s.kubelet[38157]: E0516 19:34:55.352147   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:57 research21 k8s.kubelet[38157]: E0516 19:34:57.351484   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:34:59 research21 k8s.kubelet[38157]: E0516 19:34:59.348731   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="network is not ready: container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podUID="478e2f54-5815-4945-accc-2453884e1a31"
May 16 19:35:00 research21 k8s.kubelet[38157]: I0516 19:35:00.943652   38157 kubelet_node_status.go:502] "Fast updating node status as it just became ready"
May 16 19:35:11 research21 k8s.kubelet[38157]: W0516 19:35:11.100227   38157 reflector.go:569] object-"metallb-system"/"kube-root-ca.crt": failed to list *v1.ConfigMap: configmaps "kube-root-ca.crt" is forbidden: User "system:node:research21" cannot list resource "configmaps" in API group "" in the namespace "metallb-system": no relationship found between node 'research21' and this object
May 16 19:35:11 research21 k8s.kubelet[38157]: E0516 19:35:11.101182   38157 reflector.go:166] "Unhandled Error" err="object-\"metallb-system\"/\"kube-root-ca.crt\": Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps \"kube-root-ca.crt\" is forbidden: User \"system:node:research21\" cannot list resource \"configmaps\" in API group \"\" in the namespace \"metallb-system\": no relationship found between node 'research21' and this object" logger="UnhandledError"
May 16 19:35:11 research21 k8s.kubelet[38157]: I0516 19:35:11.130986   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/d09748e0-ba21-4533-aff7-a6a92c617c59-config-volume\") pod \"coredns-56d5ddcf86-lwtgx\" (UID: \"d09748e0-ba21-4533-aff7-a6a92c617c59\") " pod="kube-system/coredns-56d5ddcf86-lwtgx"
May 16 19:35:11 research21 k8s.kubelet[38157]: I0516 19:35:11.131057   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-56s48\" (UniqueName: \"kubernetes.io/projected/7cf93103-78ba-4736-9d96-1bf79fe69175-kube-api-access-56s48\") pod \"metrics-server-8694c96fb7-csxm7\" (UID: \"7cf93103-78ba-4736-9d96-1bf79fe69175\") " pod="kube-system/metrics-server-8694c96fb7-csxm7"
May 16 19:35:11 research21 k8s.kubelet[38157]: I0516 19:35:11.131109   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-r4v9k\" (UniqueName: \"kubernetes.io/projected/d4f4f71b-54e6-4625-9650-d34f0be00e4a-kube-api-access-r4v9k\") pod \"ck-storage-rawfile-csi-controller-0\" (UID: \"d4f4f71b-54e6-4625-9650-d34f0be00e4a\") " pod="kube-system/ck-storage-rawfile-csi-controller-0"
May 16 19:35:11 research21 k8s.kubelet[38157]: I0516 19:35:11.131148   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-f5dgf\" (UniqueName: \"kubernetes.io/projected/d09748e0-ba21-4533-aff7-a6a92c617c59-kube-api-access-f5dgf\") pod \"coredns-56d5ddcf86-lwtgx\" (UID: \"d09748e0-ba21-4533-aff7-a6a92c617c59\") " pod="kube-system/coredns-56d5ddcf86-lwtgx"
May 16 19:35:11 research21 k8s.kubelet[38157]: I0516 19:35:11.131191   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cert\" (UniqueName: \"kubernetes.io/secret/b3cfbcd2-921b-46d3-9bf3-e0e5aaa18e4f-cert\") pod \"metallb-controller-86cb6b5b76-2bm2k\" (UID: \"b3cfbcd2-921b-46d3-9bf3-e0e5aaa18e4f\") " pod="metallb-system/metallb-controller-86cb6b5b76-2bm2k"
May 16 19:35:11 research21 k8s.kubelet[38157]: I0516 19:35:11.131232   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"socket-dir\" (UniqueName: \"kubernetes.io/empty-dir/d4f4f71b-54e6-4625-9650-d34f0be00e4a-socket-dir\") pod \"ck-storage-rawfile-csi-controller-0\" (UID: \"d4f4f71b-54e6-4625-9650-d34f0be00e4a\") " pod="kube-system/ck-storage-rawfile-csi-controller-0"
May 16 19:35:11 research21 k8s.kubelet[38157]: I0516 19:35:11.131270   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-6bvt9\" (UniqueName: \"kubernetes.io/projected/b3cfbcd2-921b-46d3-9bf3-e0e5aaa18e4f-kube-api-access-6bvt9\") pod \"metallb-controller-86cb6b5b76-2bm2k\" (UID: \"b3cfbcd2-921b-46d3-9bf3-e0e5aaa18e4f\") " pod="metallb-system/metallb-controller-86cb6b5b76-2bm2k"
May 16 19:35:11 research21 k8s.kubelet[38157]: I0516 19:35:11.131312   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp\" (UniqueName: \"kubernetes.io/empty-dir/7cf93103-78ba-4736-9d96-1bf79fe69175-tmp\") pod \"metrics-server-8694c96fb7-csxm7\" (UID: \"7cf93103-78ba-4736-9d96-1bf79fe69175\") " pod="kube-system/metrics-server-8694c96fb7-csxm7"
May 16 19:35:11 research21 k8s.kubelet[38157]: I0516 19:35:11.351714   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-vh2ff\" (UniqueName: \"kubernetes.io/projected/abc93faf-9a7f-42ad-82f8-9f288a0660b8-kube-api-access-vh2ff\") pod \"metallb-speaker-lxl5s\" (UID: \"abc93faf-9a7f-42ad-82f8-9f288a0660b8\") " pod="metallb-system/metallb-speaker-lxl5s"
May 16 19:35:11 research21 k8s.kubelet[38157]: I0516 19:35:11.351790   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"memberlist\" (UniqueName: \"kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist\") pod \"metallb-speaker-lxl5s\" (UID: \"abc93faf-9a7f-42ad-82f8-9f288a0660b8\") " pod="metallb-system/metallb-speaker-lxl5s"
May 16 19:35:11 research21 k8s.kubelet[38157]: I0516 19:35:11.351838   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"metallb-excludel2\" (UniqueName: \"kubernetes.io/configmap/abc93faf-9a7f-42ad-82f8-9f288a0660b8-metallb-excludel2\") pod \"metallb-speaker-lxl5s\" (UID: \"abc93faf-9a7f-42ad-82f8-9f288a0660b8\") " pod="metallb-system/metallb-speaker-lxl5s"
May 16 19:35:11 research21 k8s.kubelet[38157]: E0516 19:35:11.461035   38157 secret.go:189] Couldn't get secret metallb-system/metallb-memberlist: secret "metallb-memberlist" not found
May 16 19:35:11 research21 k8s.kubelet[38157]: E0516 19:35:11.484795   38157 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist podName:abc93faf-9a7f-42ad-82f8-9f288a0660b8 nodeName:}" failed. No retries permitted until 2025-05-16 19:35:11.96111738 -0400 EDT m=+105.098714054 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "memberlist" (UniqueName: "kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist") pod "metallb-speaker-lxl5s" (UID: "abc93faf-9a7f-42ad-82f8-9f288a0660b8") : secret "metallb-memberlist" not found
May 16 19:35:11 research21 k8s.kubelet[38157]: E0516 19:35:11.966472   38157 secret.go:189] Couldn't get secret metallb-system/metallb-memberlist: secret "metallb-memberlist" not found
May 16 19:35:11 research21 k8s.kubelet[38157]: E0516 19:35:11.966583   38157 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist podName:abc93faf-9a7f-42ad-82f8-9f288a0660b8 nodeName:}" failed. No retries permitted until 2025-05-16 19:35:12.966553982 -0400 EDT m=+106.104150669 (durationBeforeRetry 1s). Error: MountVolume.SetUp failed for volume "memberlist" (UniqueName: "kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist") pod "metallb-speaker-lxl5s" (UID: "abc93faf-9a7f-42ad-82f8-9f288a0660b8") : secret "metallb-memberlist" not found
May 16 19:35:12 research21 k8s.kubelet[38157]: E0516 19:35:12.989592   38157 secret.go:189] Couldn't get secret metallb-system/metallb-memberlist: secret "metallb-memberlist" not found
May 16 19:35:12 research21 k8s.kubelet[38157]: E0516 19:35:12.992267   38157 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist podName:abc93faf-9a7f-42ad-82f8-9f288a0660b8 nodeName:}" failed. No retries permitted until 2025-05-16 19:35:14.990763258 -0400 EDT m=+108.128359947 (durationBeforeRetry 2s). Error: MountVolume.SetUp failed for volume "memberlist" (UniqueName: "kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist") pod "metallb-speaker-lxl5s" (UID: "abc93faf-9a7f-42ad-82f8-9f288a0660b8") : secret "metallb-memberlist" not found
May 16 19:35:15 research21 k8s.kubelet[38157]: E0516 19:35:15.016840   38157 secret.go:189] Couldn't get secret metallb-system/metallb-memberlist: secret "metallb-memberlist" not found
May 16 19:35:15 research21 k8s.kubelet[38157]: E0516 19:35:15.016950   38157 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist podName:abc93faf-9a7f-42ad-82f8-9f288a0660b8 nodeName:}" failed. No retries permitted until 2025-05-16 19:35:19.016922597 -0400 EDT m=+112.154519280 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "memberlist" (UniqueName: "kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist") pod "metallb-speaker-lxl5s" (UID: "abc93faf-9a7f-42ad-82f8-9f288a0660b8") : secret "metallb-memberlist" not found
May 16 19:35:19 research21 k8s.kubelet[38157]: E0516 19:35:19.049291   38157 secret.go:189] Couldn't get secret metallb-system/metallb-memberlist: secret "metallb-memberlist" not found
May 16 19:35:19 research21 k8s.kubelet[38157]: E0516 19:35:19.049390   38157 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist podName:abc93faf-9a7f-42ad-82f8-9f288a0660b8 nodeName:}" failed. No retries permitted until 2025-05-16 19:35:27.04936449 -0400 EDT m=+120.186961173 (durationBeforeRetry 8s). Error: MountVolume.SetUp failed for volume "memberlist" (UniqueName: "kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist") pod "metallb-speaker-lxl5s" (UID: "abc93faf-9a7f-42ad-82f8-9f288a0660b8") : secret "metallb-memberlist" not found
May 16 19:35:27 research21 k8s.kubelet[38157]: E0516 19:35:27.134890   38157 secret.go:189] Couldn't get secret metallb-system/metallb-memberlist: secret "metallb-memberlist" not found
May 16 19:35:27 research21 k8s.kubelet[38157]: E0516 19:35:27.135009   38157 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist podName:abc93faf-9a7f-42ad-82f8-9f288a0660b8 nodeName:}" failed. No retries permitted until 2025-05-16 19:35:43.13498155 -0400 EDT m=+136.272578237 (durationBeforeRetry 16s). Error: MountVolume.SetUp failed for volume "memberlist" (UniqueName: "kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist") pod "metallb-speaker-lxl5s" (UID: "abc93faf-9a7f-42ad-82f8-9f288a0660b8") : secret "metallb-memberlist" not found
May 16 19:35:34 research21 k8s.kubelet[38157]: I0516 19:35:34.589759   38157 csi_plugin.go:100] kubernetes.io/csi: Trying to validate a new CSI Driver with name: rawfile.csi.openebs.io endpoint: /var/lib/kubelet/plugins/rawfile-csi/csi.sock versions: 1.0.0
May 16 19:35:34 research21 k8s.kubelet[38157]: I0516 19:35:34.589825   38157 csi_plugin.go:113] kubernetes.io/csi: Register new plugin with name: rawfile.csi.openebs.io at endpoint: /var/lib/kubelet/plugins/rawfile-csi/csi.sock
May 16 19:35:43 research21 k8s.kubelet[38157]: E0516 19:35:43.235711   38157 secret.go:189] Couldn't get secret metallb-system/metallb-memberlist: secret "metallb-memberlist" not found
May 16 19:35:43 research21 k8s.kubelet[38157]: E0516 19:35:43.235833   38157 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist podName:abc93faf-9a7f-42ad-82f8-9f288a0660b8 nodeName:}" failed. No retries permitted until 2025-05-16 19:36:15.235803357 -0400 EDT m=+168.373400044 (durationBeforeRetry 32s). Error: MountVolume.SetUp failed for volume "memberlist" (UniqueName: "kubernetes.io/secret/abc93faf-9a7f-42ad-82f8-9f288a0660b8-memberlist") pod "metallb-speaker-lxl5s" (UID: "abc93faf-9a7f-42ad-82f8-9f288a0660b8") : secret "metallb-memberlist" not found
May 16 19:35:45 research21 k8s.kubelet[38157]: I0516 19:35:45.898278   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/metrics-server-8694c96fb7-csxm7" podStartSLOduration=123.994447416 podStartE2EDuration="2m14.898178793s" podCreationTimestamp="2025-05-16 19:33:31 -0400 EDT" firstStartedPulling="2025-05-16 19:35:34.176831805 -0400 EDT m=+127.314428490" lastFinishedPulling="2025-05-16 19:35:45.080563182 -0400 EDT m=+138.218159867" observedRunningTime="2025-05-16 19:35:45.881259289 -0400 EDT m=+139.018855976" watchObservedRunningTime="2025-05-16 19:35:45.898178793 -0400 EDT m=+139.035775485"
May 16 19:35:45 research21 k8s.kubelet[38157]: I0516 19:35:45.898665   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/coredns-56d5ddcf86-lwtgx" podStartSLOduration=124.669006313 podStartE2EDuration="2m14.898650306s" podCreationTimestamp="2025-05-16 19:33:31 -0400 EDT" firstStartedPulling="2025-05-16 19:35:34.493611174 -0400 EDT m=+127.631207859" lastFinishedPulling="2025-05-16 19:35:44.723255165 -0400 EDT m=+137.860851852" observedRunningTime="2025-05-16 19:35:45.732256283 -0400 EDT m=+138.869852956" watchObservedRunningTime="2025-05-16 19:35:45.898650306 -0400 EDT m=+139.036246987"
May 16 19:35:49 research21 k8s.kubelet[38157]: I0516 19:35:49.820423   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/ck-storage-rawfile-csi-controller-0" podStartSLOduration=126.552362735 podStartE2EDuration="2m17.820399772s" podCreationTimestamp="2025-05-16 19:33:32 -0400 EDT" firstStartedPulling="2025-05-16 19:35:34.251006728 -0400 EDT m=+127.388603400" lastFinishedPulling="2025-05-16 19:35:45.519043753 -0400 EDT m=+138.656640437" observedRunningTime="2025-05-16 19:35:46.772045178 -0400 EDT m=+139.909641871" watchObservedRunningTime="2025-05-16 19:35:49.820399772 -0400 EDT m=+142.957996446"
May 16 19:35:49 research21 k8s.kubelet[38157]: I0516 19:35:49.820639   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="metallb-system/metallb-controller-86cb6b5b76-2bm2k" podStartSLOduration=124.639666849 podStartE2EDuration="2m18.820628527s" podCreationTimestamp="2025-05-16 19:33:31 -0400 EDT" firstStartedPulling="2025-05-16 19:35:34.441904911 -0400 EDT m=+127.579501594" lastFinishedPulling="2025-05-16 19:35:48.622866588 -0400 EDT m=+141.760463272" observedRunningTime="2025-05-16 19:35:49.820385444 -0400 EDT m=+142.957982149" watchObservedRunningTime="2025-05-16 19:35:49.820628527 -0400 EDT m=+142.958225201"
May 16 19:35:50 research21 k8s.kubelet[38157]: I0516 19:35:50.799440   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/ck-storage-rawfile-csi-node-z9lvt" podStartSLOduration=108.228123757 podStartE2EDuration="2m19.799414449s" podCreationTimestamp="2025-05-16 19:33:31 -0400 EDT" firstStartedPulling="2025-05-16 19:35:18.314789165 -0400 EDT m=+111.452385836" lastFinishedPulling="2025-05-16 19:35:49.886079843 -0400 EDT m=+143.023676528" observedRunningTime="2025-05-16 19:35:50.793643584 -0400 EDT m=+143.931240273" watchObservedRunningTime="2025-05-16 19:35:50.799414449 -0400 EDT m=+143.937011143"
May 16 19:36:24 research21 k8s.kubelet[38157]: I0516 19:36:24.910319   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="metallb-system/metallb-speaker-lxl5s" podStartSLOduration=65.893467605 podStartE2EDuration="1m13.910281052s" podCreationTimestamp="2025-05-16 19:35:11 -0400 EDT" firstStartedPulling="2025-05-16 19:36:15.776911683 -0400 EDT m=+168.914508354" lastFinishedPulling="2025-05-16 19:36:23.793725117 -0400 EDT m=+176.931321801" observedRunningTime="2025-05-16 19:36:24.90770489 -0400 EDT m=+178.045301629" watchObservedRunningTime="2025-05-16 19:36:24.910281052 -0400 EDT m=+178.047877744"
May 16 19:37:04 research21 k8s.kubelet[38157]: I0516 19:37:04.452810   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"controller-shared-secret\" (UniqueName: \"kubernetes.io/secret/e7a8aac7-83f9-4010-8422-751309e4233b-controller-shared-secret\") pod \"controller-0\" (UID: \"e7a8aac7-83f9-4010-8422-751309e4233b\") " pod="controller-sunbeam-controller/controller-0"
May 16 19:37:04 research21 k8s.kubelet[38157]: I0516 19:37:04.452882   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/e7a8aac7-83f9-4010-8422-751309e4233b-charm-data\") pod \"controller-0\" (UID: \"e7a8aac7-83f9-4010-8422-751309e4233b\") " pod="controller-sunbeam-controller/controller-0"
May 16 19:37:04 research21 k8s.kubelet[38157]: I0516 19:37:04.452925   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"controller-server-pem\" (UniqueName: \"kubernetes.io/secret/e7a8aac7-83f9-4010-8422-751309e4233b-controller-server-pem\") pod \"controller-0\" (UID: \"e7a8aac7-83f9-4010-8422-751309e4233b\") " pod="controller-sunbeam-controller/controller-0"
May 16 19:37:04 research21 k8s.kubelet[38157]: I0516 19:37:04.452964   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"controller-bootstrap-params\" (UniqueName: \"kubernetes.io/configmap/e7a8aac7-83f9-4010-8422-751309e4233b-controller-bootstrap-params\") pod \"controller-0\" (UID: \"e7a8aac7-83f9-4010-8422-751309e4233b\") " pod="controller-sunbeam-controller/controller-0"
May 16 19:37:04 research21 k8s.kubelet[38157]: I0516 19:37:04.453000   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-8n26d\" (UniqueName: \"kubernetes.io/projected/e7a8aac7-83f9-4010-8422-751309e4233b-kube-api-access-8n26d\") pod \"controller-0\" (UID: \"e7a8aac7-83f9-4010-8422-751309e4233b\") " pod="controller-sunbeam-controller/controller-0"
May 16 19:37:04 research21 k8s.kubelet[38157]: I0516 19:37:04.453103   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"apiserver-scratch\" (UniqueName: \"kubernetes.io/empty-dir/e7a8aac7-83f9-4010-8422-751309e4233b-apiserver-scratch\") pod \"controller-0\" (UID: \"e7a8aac7-83f9-4010-8422-751309e4233b\") " pod="controller-sunbeam-controller/controller-0"
May 16 19:37:04 research21 k8s.kubelet[38157]: I0516 19:37:04.453174   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"mongo-scratch\" (UniqueName: \"kubernetes.io/empty-dir/e7a8aac7-83f9-4010-8422-751309e4233b-mongo-scratch\") pod \"controller-0\" (UID: \"e7a8aac7-83f9-4010-8422-751309e4233b\") " pod="controller-sunbeam-controller/controller-0"
May 16 19:37:04 research21 k8s.kubelet[38157]: I0516 19:37:04.453214   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"controller-agent-conf\" (UniqueName: \"kubernetes.io/configmap/e7a8aac7-83f9-4010-8422-751309e4233b-controller-agent-conf\") pod \"controller-0\" (UID: \"e7a8aac7-83f9-4010-8422-751309e4233b\") " pod="controller-sunbeam-controller/controller-0"
May 16 19:37:04 research21 k8s.kubelet[38157]: I0516 19:37:04.453262   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-16d97cc3-52cb-4746-94b7-f1d86dd7a1af\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-16d97cc3-52cb-4746-94b7-f1d86dd7a1af\") pod \"controller-0\" (UID: \"e7a8aac7-83f9-4010-8422-751309e4233b\") " pod="controller-sunbeam-controller/controller-0"
May 16 19:37:04 research21 k8s.kubelet[38157]: I0516 19:37:04.688780   38157 operation_generator.go:557] "MountVolume.MountDevice succeeded for volume \"pvc-16d97cc3-52cb-4746-94b7-f1d86dd7a1af\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-16d97cc3-52cb-4746-94b7-f1d86dd7a1af\") pod \"controller-0\" (UID: \"e7a8aac7-83f9-4010-8422-751309e4233b\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/rawfile.csi.openebs.io/4dab54c1a2a2583085b68fed0b672348f4fe20de14ae5f4e1675809c89c5070c/globalmount\"" pod="controller-sunbeam-controller/controller-0"
May 16 19:37:51 research21 k8s.kubelet[38157]: I0516 19:37:51.310493   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="controller-sunbeam-controller/controller-0" podStartSLOduration=3.156889334 podStartE2EDuration="48.310467707s" podCreationTimestamp="2025-05-16 19:37:03 -0400 EDT" firstStartedPulling="2025-05-16 19:37:05.389547426 -0400 EDT m=+218.527144113" lastFinishedPulling="2025-05-16 19:37:50.543125801 -0400 EDT m=+263.680722486" observedRunningTime="2025-05-16 19:37:51.28956169 -0400 EDT m=+264.427158409" watchObservedRunningTime="2025-05-16 19:37:51.310467707 -0400 EDT m=+264.448064381"
May 16 19:38:13 research21 k8s.kubelet[38157]: I0516 19:38:13.268388   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-wlp6z\" (UniqueName: \"kubernetes.io/projected/75d4fb3a-9a4d-4bf3-a9fb-f452aade5822-kube-api-access-wlp6z\") pod \"modeloperator-856d6cf4bf-57fzb\" (UID: \"75d4fb3a-9a4d-4bf3-a9fb-f452aade5822\") " pod="controller-sunbeam-controller/modeloperator-856d6cf4bf-57fzb"
May 16 19:38:13 research21 k8s.kubelet[38157]: I0516 19:38:13.268516   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"modeloperator\" (UniqueName: \"kubernetes.io/configmap/75d4fb3a-9a4d-4bf3-a9fb-f452aade5822-modeloperator\") pod \"modeloperator-856d6cf4bf-57fzb\" (UID: \"75d4fb3a-9a4d-4bf3-a9fb-f452aade5822\") " pod="controller-sunbeam-controller/modeloperator-856d6cf4bf-57fzb"
May 16 19:38:15 research21 k8s.kubelet[38157]: I0516 19:38:15.294967   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="controller-sunbeam-controller/modeloperator-856d6cf4bf-57fzb" podStartSLOduration=2.294937879 podStartE2EDuration="2.294937879s" podCreationTimestamp="2025-05-16 19:38:13 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-05-16 19:38:15.290319296 -0400 EDT m=+288.427915986" watchObservedRunningTime="2025-05-16 19:38:15.294937879 -0400 EDT m=+288.432534553"
May 16 19:39:54 research21 k8s.kubelet[38157]: I0516 19:39:54.443369   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-7xf9x\" (UniqueName: \"kubernetes.io/projected/f3d30e53-805b-4c84-9e81-af3ec8feceb4-kube-api-access-7xf9x\") pod \"modeloperator-6cbd5bbd86-qqxwg\" (UID: \"f3d30e53-805b-4c84-9e81-af3ec8feceb4\") " pod="openstack/modeloperator-6cbd5bbd86-qqxwg"
May 16 19:39:54 research21 k8s.kubelet[38157]: I0516 19:39:54.443470   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"modeloperator\" (UniqueName: \"kubernetes.io/configmap/f3d30e53-805b-4c84-9e81-af3ec8feceb4-modeloperator\") pod \"modeloperator-6cbd5bbd86-qqxwg\" (UID: \"f3d30e53-805b-4c84-9e81-af3ec8feceb4\") " pod="openstack/modeloperator-6cbd5bbd86-qqxwg"
May 16 19:39:57 research21 k8s.kubelet[38157]: I0516 19:39:57.845319   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/modeloperator-6cbd5bbd86-qqxwg" podStartSLOduration=3.8452659110000003 podStartE2EDuration="3.845265911s" podCreationTimestamp="2025-05-16 19:39:54 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-05-16 19:39:57.834706745 -0400 EDT m=+390.972303434" watchObservedRunningTime="2025-05-16 19:39:57.845265911 -0400 EDT m=+390.982862583"
May 16 19:40:08 research21 k8s.kubelet[38157]: I0516 19:40:08.478348   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-8748f\" (UniqueName: \"kubernetes.io/projected/57c928da-a178-4102-95f1-647867ea16c1-kube-api-access-8748f\") pod \"ovn-relay-0\" (UID: \"57c928da-a178-4102-95f1-647867ea16c1\") " pod="openstack/ovn-relay-0"
May 16 19:40:08 research21 k8s.kubelet[38157]: I0516 19:40:08.478781   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/57c928da-a178-4102-95f1-647867ea16c1-charm-data\") pod \"ovn-relay-0\" (UID: \"57c928da-a178-4102-95f1-647867ea16c1\") " pod="openstack/ovn-relay-0"
May 16 19:40:14 research21 k8s.kubelet[38157]: I0516 19:40:14.265351   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-d6591fac-7505-4100-ab1f-f5a77373056b\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-d6591fac-7505-4100-ab1f-f5a77373056b\") pod \"rabbitmq-0\" (UID: \"67a08dc4-fcef-4826-8dfc-08f5b202eaa0\") " pod="openstack/rabbitmq-0"
May 16 19:40:14 research21 k8s.kubelet[38157]: I0516 19:40:14.265440   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-6kgmz\" (UniqueName: \"kubernetes.io/projected/67a08dc4-fcef-4826-8dfc-08f5b202eaa0-kube-api-access-6kgmz\") pod \"rabbitmq-0\" (UID: \"67a08dc4-fcef-4826-8dfc-08f5b202eaa0\") " pod="openstack/rabbitmq-0"
May 16 19:40:14 research21 k8s.kubelet[38157]: I0516 19:40:14.265503   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/67a08dc4-fcef-4826-8dfc-08f5b202eaa0-charm-data\") pod \"rabbitmq-0\" (UID: \"67a08dc4-fcef-4826-8dfc-08f5b202eaa0\") " pod="openstack/rabbitmq-0"
May 16 19:40:14 research21 k8s.kubelet[38157]: I0516 19:40:14.564180   38157 operation_generator.go:557] "MountVolume.MountDevice succeeded for volume \"pvc-d6591fac-7505-4100-ab1f-f5a77373056b\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-d6591fac-7505-4100-ab1f-f5a77373056b\") pod \"rabbitmq-0\" (UID: \"67a08dc4-fcef-4826-8dfc-08f5b202eaa0\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/rawfile.csi.openebs.io/caa943321bc0952b1a2ad10ca59f2b4feaea411622cdd2adeee9542628f585bd/globalmount\"" pod="openstack/rabbitmq-0"
May 16 19:40:18 research21 k8s.kubelet[38157]: I0516 19:40:18.119961   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-cpbhv\" (UniqueName: \"kubernetes.io/projected/19a87989-0dc5-4501-bfb8-9b62e12c0b2a-kube-api-access-cpbhv\") pod \"certificate-authority-0\" (UID: \"19a87989-0dc5-4501-bfb8-9b62e12c0b2a\") " pod="openstack/certificate-authority-0"
May 16 19:40:18 research21 k8s.kubelet[38157]: I0516 19:40:18.120042   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/19a87989-0dc5-4501-bfb8-9b62e12c0b2a-charm-data\") pod \"certificate-authority-0\" (UID: \"19a87989-0dc5-4501-bfb8-9b62e12c0b2a\") " pod="openstack/certificate-authority-0"
May 16 19:40:25 research21 k8s.kubelet[38157]: I0516 19:40:25.648379   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/certificate-authority-0" podStartSLOduration=8.648354193 podStartE2EDuration="8.648354193s" podCreationTimestamp="2025-05-16 19:40:17 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-05-16 19:40:25.637704106 -0400 EDT m=+418.775300793" watchObservedRunningTime="2025-05-16 19:40:25.648354193 -0400 EDT m=+418.785950885"
May 16 19:40:30 research21 k8s.kubelet[38157]: I0516 19:40:30.702043   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/ovn-relay-0" podStartSLOduration=7.364262523 podStartE2EDuration="22.702014176s" podCreationTimestamp="2025-05-16 19:40:08 -0400 EDT" firstStartedPulling="2025-05-16 19:40:13.573750182 -0400 EDT m=+406.711346869" lastFinishedPulling="2025-05-16 19:40:28.911501837 -0400 EDT m=+422.049098522" observedRunningTime="2025-05-16 19:40:30.685241122 -0400 EDT m=+423.822837809" watchObservedRunningTime="2025-05-16 19:40:30.702014176 -0400 EDT m=+423.839610881"
May 16 19:40:38 research21 k8s.kubelet[38157]: I0516 19:40:38.244840   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-ktjhc\" (UniqueName: \"kubernetes.io/projected/a99e13cc-ccfb-4b25-85b6-ade546d577c8-kube-api-access-ktjhc\") pod \"traefik-0\" (UID: \"a99e13cc-ccfb-4b25-85b6-ade546d577c8\") " pod="openstack/traefik-0"
May 16 19:40:38 research21 k8s.kubelet[38157]: I0516 19:40:38.244930   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/a99e13cc-ccfb-4b25-85b6-ade546d577c8-charm-data\") pod \"traefik-0\" (UID: \"a99e13cc-ccfb-4b25-85b6-ade546d577c8\") " pod="openstack/traefik-0"
May 16 19:40:38 research21 k8s.kubelet[38157]: I0516 19:40:38.245010   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-b570f973-40c0-462d-9a52-804ed452459b\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-b570f973-40c0-462d-9a52-804ed452459b\") pod \"traefik-0\" (UID: \"a99e13cc-ccfb-4b25-85b6-ade546d577c8\") " pod="openstack/traefik-0"
May 16 19:40:38 research21 k8s.kubelet[38157]: I0516 19:40:38.608195   38157 operation_generator.go:557] "MountVolume.MountDevice succeeded for volume \"pvc-b570f973-40c0-462d-9a52-804ed452459b\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-b570f973-40c0-462d-9a52-804ed452459b\") pod \"traefik-0\" (UID: \"a99e13cc-ccfb-4b25-85b6-ade546d577c8\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/rawfile.csi.openebs.io/e73516d6e3f68f38a201ed5c5f260f4a76fb8980b443fe29419cdfc3a286864d/globalmount\"" pod="openstack/traefik-0"
May 16 19:40:38 research21 k8s.kubelet[38157]: I0516 19:40:38.929946   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/rabbitmq-0" podStartSLOduration=9.127307055 podStartE2EDuration="26.929918892s" podCreationTimestamp="2025-05-16 19:40:12 -0400 EDT" firstStartedPulling="2025-05-16 19:40:19.2935796 -0400 EDT m=+412.431176283" lastFinishedPulling="2025-05-16 19:40:37.096191437 -0400 EDT m=+430.233788120" observedRunningTime="2025-05-16 19:40:38.885715415 -0400 EDT m=+432.023312100" watchObservedRunningTime="2025-05-16 19:40:38.929918892 -0400 EDT m=+432.067515584"
May 16 19:40:42 research21 k8s.kubelet[38157]: E0516 19:40:42.714563   38157 cadvisor_stats_provider.go:522] "Partial failure issuing cadvisor.ContainerInfoV2" err="partial failures: [\"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-poda99e13cc_ccfb_4b25_85b6_ade546d577c8.slice/cri-containerd-a2ff40ed2d5bb1284d7367ada43cabc9519a5ed7da02074f59aaaf0e38a3be9d.scope\": RecentStats: unable to find data in memory cache]"
May 16 19:40:43 research21 k8s.kubelet[38157]: I0516 19:40:43.464557   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-fqqt7\" (UniqueName: \"kubernetes.io/projected/79e56497-100a-456a-bede-759ccf83e1fc-kube-api-access-fqqt7\") pod \"traefik-public-0\" (UID: \"79e56497-100a-456a-bede-759ccf83e1fc\") " pod="openstack/traefik-public-0"
May 16 19:40:43 research21 k8s.kubelet[38157]: I0516 19:40:43.464641   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/79e56497-100a-456a-bede-759ccf83e1fc-charm-data\") pod \"traefik-public-0\" (UID: \"79e56497-100a-456a-bede-759ccf83e1fc\") " pod="openstack/traefik-public-0"
May 16 19:40:43 research21 k8s.kubelet[38157]: I0516 19:40:43.464698   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-d2880e52-49d9-4bfd-b7a5-342b9207a685\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-d2880e52-49d9-4bfd-b7a5-342b9207a685\") pod \"traefik-public-0\" (UID: \"79e56497-100a-456a-bede-759ccf83e1fc\") " pod="openstack/traefik-public-0"
May 16 19:40:43 research21 k8s.kubelet[38157]: I0516 19:40:43.755538   38157 operation_generator.go:557] "MountVolume.MountDevice succeeded for volume \"pvc-d2880e52-49d9-4bfd-b7a5-342b9207a685\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-d2880e52-49d9-4bfd-b7a5-342b9207a685\") pod \"traefik-public-0\" (UID: \"79e56497-100a-456a-bede-759ccf83e1fc\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/rawfile.csi.openebs.io/50df95887380087e46bc43e99b3685e08391344cac3b4d5ea9ba7855869a6e0f/globalmount\"" pod="openstack/traefik-public-0"
May 16 19:40:50 research21 k8s.kubelet[38157]: I0516 19:40:50.744537   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-2fe6db2b-18fb-4ffc-a963-a71a4db765f3\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-2fe6db2b-18fb-4ffc-a963-a71a4db765f3\") pod \"mysql-0\" (UID: \"c77b1b39-faa4-41a1-9bca-6728d9485063\") " pod="openstack/mysql-0"
May 16 19:40:50 research21 k8s.kubelet[38157]: I0516 19:40:50.745312   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/c77b1b39-faa4-41a1-9bca-6728d9485063-charm-data\") pod \"mysql-0\" (UID: \"c77b1b39-faa4-41a1-9bca-6728d9485063\") " pod="openstack/mysql-0"
May 16 19:40:50 research21 k8s.kubelet[38157]: I0516 19:40:50.746681   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-w6g7b\" (UniqueName: \"kubernetes.io/projected/c77b1b39-faa4-41a1-9bca-6728d9485063-kube-api-access-w6g7b\") pod \"mysql-0\" (UID: \"c77b1b39-faa4-41a1-9bca-6728d9485063\") " pod="openstack/mysql-0"
May 16 19:40:51 research21 k8s.kubelet[38157]: I0516 19:40:51.053095   38157 operation_generator.go:557] "MountVolume.MountDevice succeeded for volume \"pvc-2fe6db2b-18fb-4ffc-a963-a71a4db765f3\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-2fe6db2b-18fb-4ffc-a963-a71a4db765f3\") pod \"mysql-0\" (UID: \"c77b1b39-faa4-41a1-9bca-6728d9485063\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/rawfile.csi.openebs.io/56868e5db204bcf7b3fecafd886985c46e6e1094062dc93b4ea2f069d697109f/globalmount\"" pod="openstack/mysql-0"
May 16 19:40:54 research21 k8s.kubelet[38157]: I0516 19:40:54.149187   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/0ce412b2-e2b3-443c-88fc-05561df70d90-charm-data\") pod \"ovn-central-0\" (UID: \"0ce412b2-e2b3-443c-88fc-05561df70d90\") " pod="openstack/ovn-central-0"
May 16 19:40:54 research21 k8s.kubelet[38157]: I0516 19:40:54.149294   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-nn52b\" (UniqueName: \"kubernetes.io/projected/0ce412b2-e2b3-443c-88fc-05561df70d90-kube-api-access-nn52b\") pod \"ovn-central-0\" (UID: \"0ce412b2-e2b3-443c-88fc-05561df70d90\") " pod="openstack/ovn-central-0"
May 16 19:40:54 research21 k8s.kubelet[38157]: I0516 19:40:54.149344   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-420e7239-d709-4b77-a0cd-282b00fe8eaa\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-420e7239-d709-4b77-a0cd-282b00fe8eaa\") pod \"ovn-central-0\" (UID: \"0ce412b2-e2b3-443c-88fc-05561df70d90\") " pod="openstack/ovn-central-0"
May 16 19:40:54 research21 k8s.kubelet[38157]: I0516 19:40:54.482943   38157 operation_generator.go:557] "MountVolume.MountDevice succeeded for volume \"pvc-420e7239-d709-4b77-a0cd-282b00fe8eaa\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-420e7239-d709-4b77-a0cd-282b00fe8eaa\") pod \"ovn-central-0\" (UID: \"0ce412b2-e2b3-443c-88fc-05561df70d90\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/rawfile.csi.openebs.io/d71c512936522563830b2752b5d8a33d6d690153c222fcbda6854ca0862de726/globalmount\"" pod="openstack/ovn-central-0"
May 16 19:41:07 research21 k8s.kubelet[38157]: E0516 19:41:07.592238   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/6a0rnzywlucfo4rvn7y2aylcc19uaarnwsrge/ovn-northd-image@sha256:745e40f55364c53b870bd72ff9ed8d55cdf070738332260c0b917c66cff5a631\": failed to resolve reference \"registry.jujucharms.com/charm/6a0rnzywlucfo4rvn7y2aylcc19uaarnwsrge/ovn-northd-image@sha256:745e40f55364c53b870bd72ff9ed8d55cdf070738332260c0b917c66cff5a631\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed" image="registry.jujucharms.com/charm/6a0rnzywlucfo4rvn7y2aylcc19uaarnwsrge/ovn-northd-image@sha256:745e40f55364c53b870bd72ff9ed8d55cdf070738332260c0b917c66cff5a631"
May 16 19:41:11 research21 k8s.kubelet[38157]: E0516 19:41:11.812629   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/6a0rnzywlucfo4rvn7y2aylcc19uaarnwsrge/ovn-sb-db-server-image@sha256:745e40f55364c53b870bd72ff9ed8d55cdf070738332260c0b917c66cff5a631\": failed to resolve reference \"registry.jujucharms.com/charm/6a0rnzywlucfo4rvn7y2aylcc19uaarnwsrge/ovn-sb-db-server-image@sha256:745e40f55364c53b870bd72ff9ed8d55cdf070738332260c0b917c66cff5a631\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed" image="registry.jujucharms.com/charm/6a0rnzywlucfo4rvn7y2aylcc19uaarnwsrge/ovn-sb-db-server-image@sha256:745e40f55364c53b870bd72ff9ed8d55cdf070738332260c0b917c66cff5a631"
May 16 19:41:13 research21 k8s.kubelet[38157]: E0516 19:41:13.866495   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/6a0rnzywlucfo4rvn7y2aylcc19uaarnwsrge/ovn-sb-db-server-image@sha256:745e40f55364c53b870bd72ff9ed8d55cdf070738332260c0b917c66cff5a631\": failed to resolve reference \"registry.jujucharms.com/charm/6a0rnzywlucfo4rvn7y2aylcc19uaarnwsrge/ovn-sb-db-server-image@sha256:745e40f55364c53b870bd72ff9ed8d55cdf070738332260c0b917c66cff5a631\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed" image="registry.jujucharms.com/charm/6a0rnzywlucfo4rvn7y2aylcc19uaarnwsrge/ovn-sb-db-server-image@sha256:745e40f55364c53b870bd72ff9ed8d55cdf070738332260c0b917c66cff5a631"
May 16 19:41:17 research21 k8s.kubelet[38157]: I0516 19:41:17.303583   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/ovn-central-0" podStartSLOduration=13.750254638 podStartE2EDuration="25.30355197s" podCreationTimestamp="2025-05-16 19:40:52 -0400 EDT" firstStartedPulling="2025-05-16 19:41:03.523216711 -0400 EDT m=+456.660813393" lastFinishedPulling="2025-05-16 19:41:15.076514043 -0400 EDT m=+468.214110725" observedRunningTime="2025-05-16 19:41:17.296162273 -0400 EDT m=+470.433758962" watchObservedRunningTime="2025-05-16 19:41:17.30355197 -0400 EDT m=+470.441148644"
May 16 19:41:47 research21 k8s.kubelet[38157]: E0516 19:41:47.613145   38157 log.go:32] "ExecSync cmd from runtime service failed" err="rpc error: code = DeadlineExceeded desc = failed to exec in container: timeout 1s exceeded: context deadline exceeded" containerID="66162b3a67c07afe628df37b7f2d106cdfe059e212c69336fe5d8e7af48a7f4d" cmd=["mongo","--port=37017","--tls","--tlsAllowInvalidHostnames","--tlsAllowInvalidCertificates","--tlsCertificateKeyFile=/var/lib/juju/server.pem","--eval","db.adminCommand('ping')"]
May 16 19:41:54 research21 k8s.kubelet[38157]: I0516 19:41:54.488877   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/traefik-0" podStartSLOduration=9.79704556 podStartE2EDuration="1m18.488846121s" podCreationTimestamp="2025-05-16 19:40:36 -0400 EDT" firstStartedPulling="2025-05-16 19:40:43.862420375 -0400 EDT m=+437.000017055" lastFinishedPulling="2025-05-16 19:41:52.554220929 -0400 EDT m=+505.691817616" observedRunningTime="2025-05-16 19:41:54.445107185 -0400 EDT m=+507.582703905" watchObservedRunningTime="2025-05-16 19:41:54.488846121 -0400 EDT m=+507.626442812"
May 16 19:41:54 research21 k8s.kubelet[38157]: I0516 19:41:54.700089   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/traefik-public-0" podStartSLOduration=9.259903538 podStartE2EDuration="1m12.700055536s" podCreationTimestamp="2025-05-16 19:40:42 -0400 EDT" firstStartedPulling="2025-05-16 19:40:49.108975705 -0400 EDT m=+442.246572387" lastFinishedPulling="2025-05-16 19:41:52.549127695 -0400 EDT m=+505.686724385" observedRunningTime="2025-05-16 19:41:54.664995589 -0400 EDT m=+507.802592276" watchObservedRunningTime="2025-05-16 19:41:54.700055536 -0400 EDT m=+507.837652209"
May 16 19:41:57 research21 k8s.kubelet[38157]: E0516 19:41:57.542028   38157 log.go:32] "ExecSync cmd from runtime service failed" err="rpc error: code = DeadlineExceeded desc = failed to exec in container: timeout 1s exceeded: context deadline exceeded" containerID="66162b3a67c07afe628df37b7f2d106cdfe059e212c69336fe5d8e7af48a7f4d" cmd=["mongo","--port=37017","--tls","--tlsAllowInvalidHostnames","--tlsAllowInvalidCertificates","--tlsCertificateKeyFile=/var/lib/juju/server.pem","--eval","db.adminCommand('ping')"]
May 16 19:42:19 research21 k8s.kubelet[38157]: I0516 19:42:19.428808   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/9abc2614-ddda-49dc-a030-991694c25e6e-charm-data\") pod \"neutron-0\" (UID: \"9abc2614-ddda-49dc-a030-991694c25e6e\") " pod="openstack/neutron-0"
May 16 19:42:19 research21 k8s.kubelet[38157]: I0516 19:42:19.428931   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-qtjv6\" (UniqueName: \"kubernetes.io/projected/9abc2614-ddda-49dc-a030-991694c25e6e-kube-api-access-qtjv6\") pod \"neutron-0\" (UID: \"9abc2614-ddda-49dc-a030-991694c25e6e\") " pod="openstack/neutron-0"
May 16 19:42:25 research21 k8s.kubelet[38157]: I0516 19:42:25.753706   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/bc6230b0-45ba-4e2d-bd8b-017e7eb8ed0b-charm-data\") pod \"nova-mysql-router-0\" (UID: \"bc6230b0-45ba-4e2d-bd8b-017e7eb8ed0b\") " pod="openstack/nova-mysql-router-0"
May 16 19:42:25 research21 k8s.kubelet[38157]: I0516 19:42:25.753798   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-b5jzq\" (UniqueName: \"kubernetes.io/projected/bc6230b0-45ba-4e2d-bd8b-017e7eb8ed0b-kube-api-access-b5jzq\") pod \"nova-mysql-router-0\" (UID: \"bc6230b0-45ba-4e2d-bd8b-017e7eb8ed0b\") " pod="openstack/nova-mysql-router-0"
May 16 19:42:32 research21 k8s.kubelet[38157]: I0516 19:42:32.644328   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-sp29w\" (UniqueName: \"kubernetes.io/projected/4f78946b-6907-41fe-8321-f8b5e73d9ad1-kube-api-access-sp29w\") pod \"neutron-mysql-router-0\" (UID: \"4f78946b-6907-41fe-8321-f8b5e73d9ad1\") " pod="openstack/neutron-mysql-router-0"
May 16 19:42:32 research21 k8s.kubelet[38157]: I0516 19:42:32.644447   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/4f78946b-6907-41fe-8321-f8b5e73d9ad1-charm-data\") pod \"neutron-mysql-router-0\" (UID: \"4f78946b-6907-41fe-8321-f8b5e73d9ad1\") " pod="openstack/neutron-mysql-router-0"
May 16 19:42:36 research21 k8s.kubelet[38157]: E0516 19:42:36.270115   38157 cadvisor_stats_provider.go:522] "Partial failure issuing cadvisor.ContainerInfoV2" err="partial failures: [\"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod4f78946b_6907_41fe_8321_f8b5e73d9ad1.slice/cri-containerd-2d7f0e01498193ae55c81fb52d8a7e64b550a2d61513a7247e76d6b474156d8b.scope\": RecentStats: unable to find data in memory cache]"
May 16 19:42:38 research21 k8s.kubelet[38157]: I0516 19:42:38.087953   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-lvr7l\" (UniqueName: \"kubernetes.io/projected/c30b40ad-4026-4c33-8251-7eeea63ed6e1-kube-api-access-lvr7l\") pod \"nova-api-mysql-router-0\" (UID: \"c30b40ad-4026-4c33-8251-7eeea63ed6e1\") " pod="openstack/nova-api-mysql-router-0"
May 16 19:42:38 research21 k8s.kubelet[38157]: I0516 19:42:38.088039   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/c30b40ad-4026-4c33-8251-7eeea63ed6e1-charm-data\") pod \"nova-api-mysql-router-0\" (UID: \"c30b40ad-4026-4c33-8251-7eeea63ed6e1\") " pod="openstack/nova-api-mysql-router-0"
May 16 19:42:53 research21 k8s.kubelet[38157]: I0516 19:42:53.886313   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/nova-mysql-router-0" podStartSLOduration=14.861445225 podStartE2EDuration="28.886286388s" podCreationTimestamp="2025-05-16 19:42:25 -0400 EDT" firstStartedPulling="2025-05-16 19:42:37.419987254 -0400 EDT m=+550.557583959" lastFinishedPulling="2025-05-16 19:42:51.444828439 -0400 EDT m=+564.582425122" observedRunningTime="2025-05-16 19:42:53.862400604 -0400 EDT m=+566.999997293" watchObservedRunningTime="2025-05-16 19:42:53.886286388 -0400 EDT m=+567.023883079"
May 16 19:42:54 research21 k8s.kubelet[38157]: I0516 19:42:54.918345   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/nova-api-mysql-router-0" podStartSLOduration=15.377296446 podStartE2EDuration="17.918320937s" podCreationTimestamp="2025-05-16 19:42:37 -0400 EDT" firstStartedPulling="2025-05-16 19:42:48.991378534 -0400 EDT m=+562.128975217" lastFinishedPulling="2025-05-16 19:42:51.532403026 -0400 EDT m=+564.669999708" observedRunningTime="2025-05-16 19:42:54.820757726 -0400 EDT m=+567.958354429" watchObservedRunningTime="2025-05-16 19:42:54.918320937 -0400 EDT m=+568.055917611"
May 16 19:42:54 research21 k8s.kubelet[38157]: I0516 19:42:54.925338   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/mysql-0" podStartSLOduration=11.755477468 podStartE2EDuration="2m5.925311641s" podCreationTimestamp="2025-05-16 19:40:49 -0400 EDT" firstStartedPulling="2025-05-16 19:40:57.30476821 -0400 EDT m=+450.442364893" lastFinishedPulling="2025-05-16 19:42:51.474602383 -0400 EDT m=+564.612199066" observedRunningTime="2025-05-16 19:42:54.916924491 -0400 EDT m=+568.054521178" watchObservedRunningTime="2025-05-16 19:42:54.925311641 -0400 EDT m=+568.062908315"
May 16 19:42:55 research21 k8s.kubelet[38157]: I0516 19:42:55.391843   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/neutron-mysql-router-0" podStartSLOduration=17.95401482 podStartE2EDuration="23.391812255s" podCreationTimestamp="2025-05-16 19:42:32 -0400 EDT" firstStartedPulling="2025-05-16 19:42:46.10503959 -0400 EDT m=+559.242636261" lastFinishedPulling="2025-05-16 19:42:51.542837013 -0400 EDT m=+564.680433696" observedRunningTime="2025-05-16 19:42:55.331381586 -0400 EDT m=+568.468978271" watchObservedRunningTime="2025-05-16 19:42:55.391812255 -0400 EDT m=+568.529408946"
May 16 19:42:56 research21 k8s.kubelet[38157]: I0516 19:42:56.605270   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/a77e5ac2-1ca0-46b0-ac8d-e5940d37bbd0-charm-data\") pod \"cinder-0\" (UID: \"a77e5ac2-1ca0-46b0-ac8d-e5940d37bbd0\") " pod="openstack/cinder-0"
May 16 19:42:56 research21 k8s.kubelet[38157]: I0516 19:42:56.605393   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-c2txh\" (UniqueName: \"kubernetes.io/projected/a77e5ac2-1ca0-46b0-ac8d-e5940d37bbd0-kube-api-access-c2txh\") pod \"cinder-0\" (UID: \"a77e5ac2-1ca0-46b0-ac8d-e5940d37bbd0\") " pod="openstack/cinder-0"
May 16 19:43:07 research21 k8s.kubelet[38157]: I0516 19:43:07.847659   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/ece72cab-8356-4a2e-959e-dc3cd63858d9-charm-data\") pod \"glance-0\" (UID: \"ece72cab-8356-4a2e-959e-dc3cd63858d9\") " pod="openstack/glance-0"
May 16 19:43:07 research21 k8s.kubelet[38157]: I0516 19:43:07.847749   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-tpdbb\" (UniqueName: \"kubernetes.io/projected/ece72cab-8356-4a2e-959e-dc3cd63858d9-kube-api-access-tpdbb\") pod \"glance-0\" (UID: \"ece72cab-8356-4a2e-959e-dc3cd63858d9\") " pod="openstack/glance-0"
May 16 19:43:07 research21 k8s.kubelet[38157]: I0516 19:43:07.847816   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-89ac7384-54c8-41da-a0eb-83af78f85047\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-89ac7384-54c8-41da-a0eb-83af78f85047\") pod \"glance-0\" (UID: \"ece72cab-8356-4a2e-959e-dc3cd63858d9\") " pod="openstack/glance-0"
May 16 19:43:08 research21 k8s.kubelet[38157]: I0516 19:43:08.293905   38157 operation_generator.go:557] "MountVolume.MountDevice succeeded for volume \"pvc-89ac7384-54c8-41da-a0eb-83af78f85047\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-89ac7384-54c8-41da-a0eb-83af78f85047\") pod \"glance-0\" (UID: \"ece72cab-8356-4a2e-959e-dc3cd63858d9\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/rawfile.csi.openebs.io/49e05df2e1703f8edce471128b72dd8265f23232ebeae70c6d16e63558363963/globalmount\"" pod="openstack/glance-0"
May 16 19:43:08 research21 k8s.kubelet[38157]: I0516 19:43:08.837883   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/42a0e6ce-20da-407d-9055-f1e40fc28e29-charm-data\") pod \"glance-mysql-router-0\" (UID: \"42a0e6ce-20da-407d-9055-f1e40fc28e29\") " pod="openstack/glance-mysql-router-0"
May 16 19:43:08 research21 k8s.kubelet[38157]: I0516 19:43:08.838005   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-k6n5s\" (UniqueName: \"kubernetes.io/projected/42a0e6ce-20da-407d-9055-f1e40fc28e29-kube-api-access-k6n5s\") pod \"glance-mysql-router-0\" (UID: \"42a0e6ce-20da-407d-9055-f1e40fc28e29\") " pod="openstack/glance-mysql-router-0"
May 16 19:43:11 research21 k8s.kubelet[38157]: I0516 19:43:11.822547   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/2c5039ac-3636-41a3-978e-5225ff4c3882-charm-data\") pod \"nova-cell-mysql-router-0\" (UID: \"2c5039ac-3636-41a3-978e-5225ff4c3882\") " pod="openstack/nova-cell-mysql-router-0"
May 16 19:43:11 research21 k8s.kubelet[38157]: I0516 19:43:11.826520   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-5gwtd\" (UniqueName: \"kubernetes.io/projected/2c5039ac-3636-41a3-978e-5225ff4c3882-kube-api-access-5gwtd\") pod \"nova-cell-mysql-router-0\" (UID: \"2c5039ac-3636-41a3-978e-5225ff4c3882\") " pod="openstack/nova-cell-mysql-router-0"
May 16 19:43:20 research21 k8s.kubelet[38157]: I0516 19:43:20.114811   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/4a9e5f3c-87a0-4a5c-8b18-52ebe3baf44a-charm-data\") pod \"cinder-mysql-router-0\" (UID: \"4a9e5f3c-87a0-4a5c-8b18-52ebe3baf44a\") " pod="openstack/cinder-mysql-router-0"
May 16 19:43:20 research21 k8s.kubelet[38157]: I0516 19:43:20.114922   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-779cx\" (UniqueName: \"kubernetes.io/projected/4a9e5f3c-87a0-4a5c-8b18-52ebe3baf44a-kube-api-access-779cx\") pod \"cinder-mysql-router-0\" (UID: \"4a9e5f3c-87a0-4a5c-8b18-52ebe3baf44a\") " pod="openstack/cinder-mysql-router-0"
May 16 19:43:26 research21 k8s.kubelet[38157]: I0516 19:43:26.416892   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-sgdvh\" (UniqueName: \"kubernetes.io/projected/978123ca-9a04-46e6-817d-bd32c889ff8e-kube-api-access-sgdvh\") pod \"keystone-mysql-router-0\" (UID: \"978123ca-9a04-46e6-817d-bd32c889ff8e\") " pod="openstack/keystone-mysql-router-0"
May 16 19:43:26 research21 k8s.kubelet[38157]: I0516 19:43:26.417010   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/978123ca-9a04-46e6-817d-bd32c889ff8e-charm-data\") pod \"keystone-mysql-router-0\" (UID: \"978123ca-9a04-46e6-817d-bd32c889ff8e\") " pod="openstack/keystone-mysql-router-0"
May 16 19:43:31 research21 k8s.kubelet[38157]: I0516 19:43:31.787199   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/94a90393-441a-4405-9c48-331369cd9170-charm-data\") pod \"horizon-mysql-router-0\" (UID: \"94a90393-441a-4405-9c48-331369cd9170\") " pod="openstack/horizon-mysql-router-0"
May 16 19:43:31 research21 k8s.kubelet[38157]: I0516 19:43:31.787333   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-pl5pd\" (UniqueName: \"kubernetes.io/projected/94a90393-441a-4405-9c48-331369cd9170-kube-api-access-pl5pd\") pod \"horizon-mysql-router-0\" (UID: \"94a90393-441a-4405-9c48-331369cd9170\") " pod="openstack/horizon-mysql-router-0"
May 16 19:43:34 research21 k8s.kubelet[38157]: I0516 19:43:34.150436   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/glance-mysql-router-0" podStartSLOduration=26.150407308 podStartE2EDuration="26.150407308s" podCreationTimestamp="2025-05-16 19:43:08 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-05-16 19:43:34.141172761 -0400 EDT m=+607.278769463" watchObservedRunningTime="2025-05-16 19:43:34.150407308 -0400 EDT m=+607.288003999"
May 16 19:43:34 research21 k8s.kubelet[38157]: I0516 19:43:34.237673   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/nova-cell-mysql-router-0" podStartSLOduration=23.237639716 podStartE2EDuration="23.237639716s" podCreationTimestamp="2025-05-16 19:43:11 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-05-16 19:43:34.214366379 -0400 EDT m=+607.351963079" watchObservedRunningTime="2025-05-16 19:43:34.237639716 -0400 EDT m=+607.375236390"
May 16 19:43:38 research21 k8s.kubelet[38157]: I0516 19:43:38.241848   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-tlwfn\" (UniqueName: \"kubernetes.io/projected/d657b5da-8fe8-4251-98f6-ed7f7127e753-kube-api-access-tlwfn\") pod \"placement-0\" (UID: \"d657b5da-8fe8-4251-98f6-ed7f7127e753\") " pod="openstack/placement-0"
May 16 19:43:38 research21 k8s.kubelet[38157]: I0516 19:43:38.242008   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/d657b5da-8fe8-4251-98f6-ed7f7127e753-charm-data\") pod \"placement-0\" (UID: \"d657b5da-8fe8-4251-98f6-ed7f7127e753\") " pod="openstack/placement-0"
May 16 19:43:39 research21 k8s.kubelet[38157]: I0516 19:43:39.673927   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/a89c8beb-fed1-421c-83bc-7183ff8d9332-charm-data\") pod \"placement-mysql-router-0\" (UID: \"a89c8beb-fed1-421c-83bc-7183ff8d9332\") " pod="openstack/placement-mysql-router-0"
May 16 19:43:39 research21 k8s.kubelet[38157]: I0516 19:43:39.674035   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-8vm5p\" (UniqueName: \"kubernetes.io/projected/a89c8beb-fed1-421c-83bc-7183ff8d9332-kube-api-access-8vm5p\") pod \"placement-mysql-router-0\" (UID: \"a89c8beb-fed1-421c-83bc-7183ff8d9332\") " pod="openstack/placement-mysql-router-0"
May 16 19:43:52 research21 k8s.kubelet[38157]: I0516 19:43:52.360924   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/cinder-mysql-router-0" podStartSLOduration=33.360895735 podStartE2EDuration="33.360895735s" podCreationTimestamp="2025-05-16 19:43:19 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-05-16 19:43:52.335527148 -0400 EDT m=+625.473123833" watchObservedRunningTime="2025-05-16 19:43:52.360895735 -0400 EDT m=+625.498492409"
May 16 19:43:53 research21 k8s.kubelet[38157]: I0516 19:43:53.915190   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-a6e89598-2ce1-43cb-8a45-f13a5e222a93\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-a6e89598-2ce1-43cb-8a45-f13a5e222a93\") pod \"keystone-0\" (UID: \"a4d99034-ebd2-404e-a805-9551caf25ee0\") " pod="openstack/keystone-0"
May 16 19:43:54 research21 k8s.kubelet[38157]: I0516 19:43:54.666343   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/a4d99034-ebd2-404e-a805-9551caf25ee0-charm-data\") pod \"keystone-0\" (UID: \"a4d99034-ebd2-404e-a805-9551caf25ee0\") " pod="openstack/keystone-0"
May 16 19:43:54 research21 k8s.kubelet[38157]: I0516 19:43:54.666430   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-cf2ee45a-9ea1-4f37-afa6-d7fb8e8bf7b5\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-cf2ee45a-9ea1-4f37-afa6-d7fb8e8bf7b5\") pod \"keystone-0\" (UID: \"a4d99034-ebd2-404e-a805-9551caf25ee0\") " pod="openstack/keystone-0"
May 16 19:43:54 research21 k8s.kubelet[38157]: I0516 19:43:54.678307   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-bmcz4\" (UniqueName: \"kubernetes.io/projected/a4d99034-ebd2-404e-a805-9551caf25ee0-kube-api-access-bmcz4\") pod \"keystone-0\" (UID: \"a4d99034-ebd2-404e-a805-9551caf25ee0\") " pod="openstack/keystone-0"
May 16 19:43:54 research21 k8s.kubelet[38157]: I0516 19:43:54.849748   38157 operation_generator.go:557] "MountVolume.MountDevice succeeded for volume \"pvc-a6e89598-2ce1-43cb-8a45-f13a5e222a93\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-a6e89598-2ce1-43cb-8a45-f13a5e222a93\") pod \"keystone-0\" (UID: \"a4d99034-ebd2-404e-a805-9551caf25ee0\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/rawfile.csi.openebs.io/5ac734e32095add9451aa4e10b619ae9fe3bfcd1c4a28647c4eae8c332d0d8ea/globalmount\"" pod="openstack/keystone-0"
May 16 19:43:55 research21 k8s.kubelet[38157]: I0516 19:43:55.697333   38157 operation_generator.go:557] "MountVolume.MountDevice succeeded for volume \"pvc-cf2ee45a-9ea1-4f37-afa6-d7fb8e8bf7b5\" (UniqueName: \"kubernetes.io/csi/rawfile.csi.openebs.io^pvc-cf2ee45a-9ea1-4f37-afa6-d7fb8e8bf7b5\") pod \"keystone-0\" (UID: \"a4d99034-ebd2-404e-a805-9551caf25ee0\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/rawfile.csi.openebs.io/ace920904de4ef2ee53d4a22d9f5c5743d2e002748274b30c8b3f8bde8dc16b6/globalmount\"" pod="openstack/keystone-0"
May 16 19:43:59 research21 k8s.kubelet[38157]: I0516 19:43:59.046721   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-ltkmc\" (UniqueName: \"kubernetes.io/projected/2bb4341e-6200-4667-9114-612847755fe1-kube-api-access-ltkmc\") pod \"horizon-0\" (UID: \"2bb4341e-6200-4667-9114-612847755fe1\") " pod="openstack/horizon-0"
May 16 19:43:59 research21 k8s.kubelet[38157]: I0516 19:43:59.051094   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/2bb4341e-6200-4667-9114-612847755fe1-charm-data\") pod \"horizon-0\" (UID: \"2bb4341e-6200-4667-9114-612847755fe1\") " pod="openstack/horizon-0"
May 16 19:44:08 research21 k8s.kubelet[38157]: E0516 19:44:08.416212   38157 kubelet.go:2579] "Housekeeping took longer than expected" err="housekeeping took too long" expected="1s" actual="1.042s"
May 16 19:44:08 research21 k8s.kubelet[38157]: I0516 19:44:08.532868   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"charm-data\" (UniqueName: \"kubernetes.io/empty-dir/0689787d-3910-4f26-84a4-d98f21f25a2b-charm-data\") pod \"nova-0\" (UID: \"0689787d-3910-4f26-84a4-d98f21f25a2b\") " pod="openstack/nova-0"
May 16 19:44:08 research21 k8s.kubelet[38157]: I0516 19:44:08.543158   38157 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-mvntj\" (UniqueName: \"kubernetes.io/projected/0689787d-3910-4f26-84a4-d98f21f25a2b-kube-api-access-mvntj\") pod \"nova-0\" (UID: \"0689787d-3910-4f26-84a4-d98f21f25a2b\") " pod="openstack/nova-0"
May 16 19:44:12 research21 k8s.kubelet[38157]: I0516 19:44:12.408421   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/keystone-mysql-router-0" podStartSLOduration=46.408393773 podStartE2EDuration="46.408393773s" podCreationTimestamp="2025-05-16 19:43:26 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-05-16 19:44:12.257618741 -0400 EDT m=+645.395215444" watchObservedRunningTime="2025-05-16 19:44:12.408393773 -0400 EDT m=+645.545990447"
May 16 19:44:13 research21 k8s.kubelet[38157]: I0516 19:44:13.638867   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/horizon-mysql-router-0" podStartSLOduration=42.638833296 podStartE2EDuration="42.638833296s" podCreationTimestamp="2025-05-16 19:43:31 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-05-16 19:44:13.589897269 -0400 EDT m=+646.727493956" watchObservedRunningTime="2025-05-16 19:44:13.638833296 -0400 EDT m=+646.776430007"
May 16 19:44:18 research21 k8s.kubelet[38157]: I0516 19:44:18.165016   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/placement-mysql-router-0" podStartSLOduration=39.164982539 podStartE2EDuration="39.164982539s" podCreationTimestamp="2025-05-16 19:43:39 -0400 EDT" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-05-16 19:44:18.102878467 -0400 EDT m=+651.240475160" watchObservedRunningTime="2025-05-16 19:44:18.164982539 -0400 EDT m=+651.302579224"
May 16 19:44:27 research21 k8s.kubelet[38157]: E0516 19:44:27.715678   38157 log.go:32] "ExecSync cmd from runtime service failed" err="rpc error: code = DeadlineExceeded desc = failed to exec in container: timeout 1s exceeded: context deadline exceeded" containerID="66162b3a67c07afe628df37b7f2d106cdfe059e212c69336fe5d8e7af48a7f4d" cmd=["mongo","--port=37017","--tls","--tlsAllowInvalidHostnames","--tlsAllowInvalidCertificates","--tlsCertificateKeyFile=/var/lib/juju/server.pem","--eval","db.adminCommand('ping')"]
May 16 19:44:28 research21 k8s.kubelet[38157]: E0516 19:44:28.555194   38157 cadvisor_stats_provider.go:522] "Partial failure issuing cadvisor.ContainerInfoV2" err="partial failures: [\"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-poda4d99034_ebd2_404e_a805_9551caf25ee0.slice/cri-containerd-949cbe8ece1ea7105a1168b0c4f9d9a069da707cf83d324bcabe00e1ead9a3c0.scope\": RecentStats: unable to find data in memory cache], [\"/kubepods.slice/kubepods-besteffort.slice/kubepods-besteffort-pod2bb4341e_6200_4667_9114_612847755fe1.slice/cri-containerd-b12d15261e38a21a326f7b5c6dc764ffdc89ff204eb706dd94d9b6e198e68442.scope\": RecentStats: unable to find data in memory cache]"
May 16 19:47:50 research21 k8s.kubelet[38157]: I0516 19:47:50.380999   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/neutron-0" podStartSLOduration=14.346839123 podStartE2EDuration="5m31.380967751s" podCreationTimestamp="2025-05-16 19:42:19 -0400 EDT" firstStartedPulling="2025-05-16 19:42:29.964590274 -0400 EDT m=+543.102186959" lastFinishedPulling="2025-05-16 19:47:46.9987189 -0400 EDT m=+860.136315587" observedRunningTime="2025-05-16 19:47:50.340629141 -0400 EDT m=+863.478225846" watchObservedRunningTime="2025-05-16 19:47:50.380967751 -0400 EDT m=+863.518564424"
May 16 19:48:14 research21 k8s.kubelet[38157]: I0516 19:48:14.363295   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/placement-0" podStartSLOduration=40.109000924 podStartE2EDuration="4m37.363265553s" podCreationTimestamp="2025-05-16 19:43:37 -0400 EDT" firstStartedPulling="2025-05-16 19:44:10.142839145 -0400 EDT m=+643.280435827" lastFinishedPulling="2025-05-16 19:48:07.397103771 -0400 EDT m=+880.534700456" observedRunningTime="2025-05-16 19:48:13.595786798 -0400 EDT m=+886.733383497" watchObservedRunningTime="2025-05-16 19:48:14.363265553 -0400 EDT m=+887.500862244"
May 16 19:48:39 research21 k8s.kubelet[38157]: I0516 19:48:39.667969   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/keystone-0" podStartSLOduration=47.549784421 podStartE2EDuration="4m49.667942209s" podCreationTimestamp="2025-05-16 19:43:50 -0400 EDT" firstStartedPulling="2025-05-16 19:44:32.557038165 -0400 EDT m=+665.694634847" lastFinishedPulling="2025-05-16 19:48:34.67519595 -0400 EDT m=+907.812792635" observedRunningTime="2025-05-16 19:48:39.643028989 -0400 EDT m=+912.780625676" watchObservedRunningTime="2025-05-16 19:48:39.667942209 -0400 EDT m=+912.805538883"
May 16 19:49:45 research21 k8s.kubelet[38157]: E0516 19:49:45.853571   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/ebs3142hrttofbph7b3nwcdnxsnf9mj4cqefz/cinder-scheduler-image@sha256:45e3776f1090a77572e0a72bcc4ac26043e6f79f4a7b578bec8577215d773264\": failed to resolve reference \"registry.jujucharms.com/charm/ebs3142hrttofbph7b3nwcdnxsnf9mj4cqefz/cinder-scheduler-image@sha256:45e3776f1090a77572e0a72bcc4ac26043e6f79f4a7b578bec8577215d773264\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed" image="registry.jujucharms.com/charm/ebs3142hrttofbph7b3nwcdnxsnf9mj4cqefz/cinder-scheduler-image@sha256:45e3776f1090a77572e0a72bcc4ac26043e6f79f4a7b578bec8577215d773264"
May 16 19:49:50 research21 k8s.kubelet[38157]: I0516 19:49:50.698529   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/cinder-0" podStartSLOduration=18.047579856 podStartE2EDuration="6m55.698495163s" podCreationTimestamp="2025-05-16 19:42:55 -0400 EDT" firstStartedPulling="2025-05-16 19:43:09.313547228 -0400 EDT m=+582.451143913" lastFinishedPulling="2025-05-16 19:49:46.964462533 -0400 EDT m=+980.102059220" observedRunningTime="2025-05-16 19:49:50.665915004 -0400 EDT m=+983.803511695" watchObservedRunningTime="2025-05-16 19:49:50.698495163 -0400 EDT m=+983.836091855"
May 16 19:50:05 research21 k8s.kubelet[38157]: I0516 19:50:05.049617   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/glance-0" podStartSLOduration=21.587699117 podStartE2EDuration="6m59.049589969s" podCreationTimestamp="2025-05-16 19:43:06 -0400 EDT" firstStartedPulling="2025-05-16 19:43:23.446614379 -0400 EDT m=+596.584211061" lastFinishedPulling="2025-05-16 19:50:00.908505229 -0400 EDT m=+994.046101913" observedRunningTime="2025-05-16 19:50:05.047423608 -0400 EDT m=+998.185020282" watchObservedRunningTime="2025-05-16 19:50:05.049589969 -0400 EDT m=+998.187186653"
May 16 19:50:13 research21 k8s.kubelet[38157]: E0516 19:50:13.154038   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-conductor-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-conductor-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed" image="registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-conductor-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9"
May 16 19:50:13 research21 k8s.kubelet[38157]: I0516 19:50:13.280826   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/horizon-0" podStartSLOduration=39.527075943 podStartE2EDuration="6m16.280795908s" podCreationTimestamp="2025-05-16 19:43:57 -0400 EDT" firstStartedPulling="2025-05-16 19:44:33.215647288 -0400 EDT m=+666.353243975" lastFinishedPulling="2025-05-16 19:50:09.969367253 -0400 EDT m=+1003.106963940" observedRunningTime="2025-05-16 19:50:13.275755079 -0400 EDT m=+1006.413351782" watchObservedRunningTime="2025-05-16 19:50:13.280795908 -0400 EDT m=+1006.418392581"
May 16 19:50:19 research21 k8s.kubelet[38157]: E0516 19:50:19.022762   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-scheduler-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-scheduler-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed" image="registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-scheduler-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9"
May 16 19:50:20 research21 k8s.kubelet[38157]: E0516 19:50:20.830852   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-scheduler-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-scheduler-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed" image="registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-scheduler-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9"
May 16 19:51:07 research21 k8s.kubelet[38157]: E0516 19:51:07.437298   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = DeadlineExceeded desc = failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to do request: Head \"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": dial tcp 185.125.188.51:443: i/o timeout" image="registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9"
May 16 19:51:38 research21 k8s.kubelet[38157]: E0516 19:51:38.158473   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to do request: Head \"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": dial tcp: lookup registry.jujucharms.com on 127.0.0.53:53: server misbehaving" image="registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9"
May 16 19:52:11 research21 k8s.kubelet[38157]: E0516 19:52:11.952118   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to do request: Head \"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": dial tcp: lookup registry.jujucharms.com on 127.0.0.53:53: server misbehaving" image="registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9"
May 16 19:52:42 research21 k8s.kubelet[38157]: E0516 19:52:42.670996   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to do request: Head \"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": dial tcp: lookup registry.jujucharms.com on 127.0.0.53:53: server misbehaving" image="registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9"
May 16 19:52:42 research21 k8s.kubelet[38157]: E0516 19:52:42.671330   38157 kuberuntime_manager.go:1341] "Unhandled Error" err="container &Container{Name:nova-spiceproxy,Image:registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9,Command:[/charm/bin/pebble],Args:[run --create-dirs --hold --http :38816 --verbose],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:JUJU_CONTAINER_NAME,Value:nova-spiceproxy,ValueFrom:nil,},EnvVar{Name:PEBBLE_SOCKET,Value:/charm/container/pebble.socket,ValueFrom:nil,},EnvVar{Name:PEBBLE,Value:/charm/container/pebble,ValueFrom:nil,},EnvVar{Name:PEBBLE_COPY_ONCE,Value:/var/lib/pebble/default,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:charm-data,ReadOnly:true,MountPath:/charm/bin/pebble,SubPath:charm/bin/pebble,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},VolumeMount{Name:charm-data,ReadOnly:false,MountPath:/charm/container,SubPath:charm/containers/nova-spiceproxy,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},VolumeMount{Name:kube-api-access-mvntj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/v1/health?level=alive,Port:{0 38816 },Host:,Scheme:HTTP,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:0,TimeoutSeconds:1,PeriodSeconds:5,SuccessThreshold:1,FailureThreshold:3,TerminationGracePeriodSeconds:nil,},ReadinessProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/v1/health?level=ready,Port:{0 38816 },Host:,Scheme:HTTP,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:0,TimeoutSeconds:1,PeriodSeconds:5,SuccessThreshold:1,FailureThreshold:1,TerminationGracePeriodSeconds:nil,},Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:*0,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:*0,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:&Probe{ProbeHandler:ProbeHandler{Exec:nil,HTTPGet:&HTTPGetAction{Path:/v1/health?level=alive,Port:{0 38816 },Host:,Scheme:HTTP,HTTPHeaders:[]HTTPHeader{},},TCPSocket:nil,GRPC:nil,},InitialDelaySeconds:0,TimeoutSeconds:1,PeriodSeconds:1,SuccessThreshold:1,FailureThreshold:30,TerminationGracePeriodSeconds:nil,},ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod nova-0_openstack(0689787d-3910-4f26-84a4-d98f21f25a2b): ErrImagePull: [rpc error: code = DeadlineExceeded desc = failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to do request: Head \"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": dial tcp 185.125.188.51:443: i/o timeout, failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to do request: Head \"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": dial tcp: lookup registry.jujucharms.com on 127.0.0.53:53: server misbehaving]" logger="UnhandledError"
May 16 19:52:42 research21 k8s.kubelet[38157]: E0516 19:52:42.672703   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"nova-spiceproxy\" with ErrImagePull: \"[rpc error: code = DeadlineExceeded desc = failed to pull and unpack image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to resolve reference \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to do request: Head \\\"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": dial tcp 185.125.188.51:443: i/o timeout, failed to pull and unpack image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to resolve reference \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to do request: Head \\\"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": dial tcp: lookup registry.jujucharms.com on 127.0.0.53:53: server misbehaving]\"" pod="openstack/nova-0" podUID="0689787d-3910-4f26-84a4-d98f21f25a2b"
May 16 19:52:43 research21 k8s.kubelet[38157]: E0516 19:52:43.187706   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"nova-spiceproxy\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": ErrImagePull: [rpc error: code = DeadlineExceeded desc = failed to pull and unpack image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to resolve reference \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to do request: Head \\\"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": dial tcp 185.125.188.51:443: i/o timeout, failed to pull and unpack image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to resolve reference \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to do request: Head \\\"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": dial tcp: lookup registry.jujucharms.com on 127.0.0.53:53: server misbehaving]\"" pod="openstack/nova-0" podUID="0689787d-3910-4f26-84a4-d98f21f25a2b"
May 16 19:52:44 research21 k8s.kubelet[38157]: E0516 19:52:44.138429   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"nova-spiceproxy\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": ErrImagePull: [rpc error: code = DeadlineExceeded desc = failed to pull and unpack image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to resolve reference \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to do request: Head \\\"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": dial tcp 185.125.188.51:443: i/o timeout, failed to pull and unpack image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to resolve reference \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to do request: Head \\\"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": dial tcp: lookup registry.jujucharms.com on 127.0.0.53:53: server misbehaving]\"" pod="openstack/nova-0" podUID="0689787d-3910-4f26-84a4-d98f21f25a2b"
May 16 19:52:45 research21 k8s.kubelet[38157]: E0516 19:52:45.148735   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"nova-spiceproxy\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": ErrImagePull: [rpc error: code = DeadlineExceeded desc = failed to pull and unpack image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to resolve reference \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to do request: Head \\\"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": dial tcp 185.125.188.51:443: i/o timeout, failed to pull and unpack image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to resolve reference \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to do request: Head \\\"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": dial tcp: lookup registry.jujucharms.com on 127.0.0.53:53: server misbehaving]\"" pod="openstack/nova-0" podUID="0689787d-3910-4f26-84a4-d98f21f25a2b"
May 16 19:52:46 research21 k8s.kubelet[38157]: E0516 19:52:46.151333   38157 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"nova-spiceproxy\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": ErrImagePull: [rpc error: code = DeadlineExceeded desc = failed to pull and unpack image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to resolve reference \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to do request: Head \\\"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": dial tcp 185.125.188.51:443: i/o timeout, failed to pull and unpack image \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to resolve reference \\\"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": failed to do request: Head \\\"https://registry.jujucharms.com/v2/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image/manifests/sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\\\": dial tcp: lookup registry.jujucharms.com on 127.0.0.53:53: server misbehaving]\"" pod="openstack/nova-0" podUID="0689787d-3910-4f26-84a4-d98f21f25a2b"
May 16 19:53:01 research21 k8s.kubelet[38157]: E0516 19:53:01.944143   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed" image="registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9"
May 16 19:53:03 research21 k8s.kubelet[38157]: E0516 19:53:03.764398   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed" image="registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9"
May 16 19:53:05 research21 k8s.kubelet[38157]: E0516 19:53:05.154538   38157 log.go:32] "PullImage from image service failed" err="rpc error: code = Unknown desc = failed to pull and unpack image \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": failed to resolve reference \"registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed" image="registry.jujucharms.com/charm/cxpoxnvod1u9zuavqxnfmu8pseyhoa3d2np1q/nova-spiceproxy-image@sha256:40106c0a0b2972c865cf453956a00b3a32422971601f69092158b93c068503f9"
May 16 19:53:09 research21 k8s.kubelet[38157]: I0516 19:53:09.544230   38157 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="openstack/nova-0" podStartSLOduration=35.872284464 podStartE2EDuration="9m2.544171339s" podCreationTimestamp="2025-05-16 19:44:07 -0400 EDT" firstStartedPulling="2025-05-16 19:44:39.85718021 -0400 EDT m=+672.994776897" lastFinishedPulling="2025-05-16 19:53:06.529067085 -0400 EDT m=+1179.666663772" observedRunningTime="2025-05-16 19:53:09.526163781 -0400 EDT m=+1182.663760481" watchObservedRunningTime="2025-05-16 19:53:09.544171339 -0400 EDT m=+1182.681768026"
May 16 20:03:27 research21 k8s.kubelet[38157]: E0516 20:03:27.338083   38157 log.go:32] "ExecSync cmd from runtime service failed" err="rpc error: code = DeadlineExceeded desc = failed to exec in container: timeout 1s exceeded: context deadline exceeded" containerID="66162b3a67c07afe628df37b7f2d106cdfe059e212c69336fe5d8e7af48a7f4d" cmd=["mongo","--port=37017","--tls","--tlsAllowInvalidHostnames","--tlsAllowInvalidCertificates","--tlsCertificateKeyFile=/var/lib/juju/server.pem","--eval","db.adminCommand('ping')"]
May 17 18:40:47 research21 k8s.kubelet[38157]: E0517 18:40:47.619801   38157 log.go:32] "ExecSync cmd from runtime service failed" err="rpc error: code = DeadlineExceeded desc = failed to exec in container: timeout 1s exceeded: context deadline exceeded" containerID="66162b3a67c07afe628df37b7f2d106cdfe059e212c69336fe5d8e7af48a7f4d" cmd=["mongo","--port=37017","--tls","--tlsAllowInvalidHostnames","--tlsAllowInvalidCertificates","--tlsCertificateKeyFile=/var/lib/juju/server.pem","--eval","db.adminCommand('ping')"]
