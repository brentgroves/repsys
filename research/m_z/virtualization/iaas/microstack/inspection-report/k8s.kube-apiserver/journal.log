May 16 19:33:15 research21 systemd[1]: Started snap.k8s.kube-apiserver.service - Service for snap application k8s.kube-apiserver.
May 16 19:33:15 research21 k8s.kube-apiserver[37236]: + ulimit -c unlimited
May 16 19:33:15 research21 k8s.kube-apiserver[37236]: + export GOTRACEBACK=crash
May 16 19:33:15 research21 k8s.kube-apiserver[37236]: + GOTRACEBACK=crash
May 16 19:33:15 research21 k8s.kube-apiserver[37236]: + [[ -f /var/snap/k8s/common/args/kube-apiserver-env ]]
May 16 19:33:15 research21 k8s.kube-apiserver[37236]: + exec /snap/k8s/2500/bin/kube-apiserver --advertise-address=172.24.188.57 --allow-privileged=true --anonymous-auth=false --authentication-token-webhook-config-file=/var/snap/k8s/common/args/conf.d/auth-token-webhook.conf --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/client-ca.crt --enable-admission-plugins=NodeRestriction --etcd-servers=unix:///var/snap/k8s/common/var/lib/k8s-dqlite/k8s-dqlite.sock --feature-gates=WatchList=false --kubelet-certificate-authority=/etc/kubernetes/pki/ca.crt --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP --profiling=false --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --request-timeout=300s --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-issuer=https://kubernetes.default.svc --service-account-key-file=/etc/kubernetes/pki/serviceaccount.key --service-account-signing-key-file=/etc/kubernetes/pki/serviceaccount.key --service-cluster-ip-range=10.152.183.0/24 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-cipher-suites=TLS_AES_128_GCM_SHA256,TLS_AES_256_GCM_SHA384,TLS_CHACHA20_POLY1305_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_RSA_WITH_3DES_EDE_CBC_SHA,TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_256_CBC_SHA,TLS_RSA_WITH_AES_256_GCM_SHA384 --tls-min-version=VersionTLS12 --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
May 16 19:33:15 research21 k8s.kube-apiserver[37236]: W0516 19:33:15.579288   37236 registry.go:256] calling componentGlobalsRegistry.AddFlags more than once, the registry will be set by the latest flags
May 16 19:33:15 research21 k8s.kube-apiserver[37236]: I0516 19:33:15.580000   37236 options.go:238] external host was not specified, using 172.24.188.57
May 16 19:33:15 research21 k8s.kube-apiserver[37236]: I0516 19:33:15.583437   37236 server.go:143] Version: v1.32.2
May 16 19:33:15 research21 k8s.kube-apiserver[37236]: I0516 19:33:15.583491   37236 server.go:145] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK="crash"
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.035321   37236 shared_informer.go:313] Waiting for caches to sync for node_authorizer
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.055993   37236 shared_informer.go:313] Waiting for caches to sync for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.068518   37236 plugins.go:157] Loaded 13 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionPolicy,MutatingAdmissionWebhook.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.068563   37236 plugins.go:160] Loaded 13 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,ClusterTrustBundleAttest,CertificateSubjectRestriction,ValidatingAdmissionPolicy,ValidatingAdmissionWebhook,ResourceQuota.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.069108   37236 instance.go:233] Using reconciler: lease
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: E0516 19:33:17.090343   37236 feature_support_checker.go:165] "Failed to parse etcd version" err="could not parse \"\" as version" version=""
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.090385   37236 feature_support_checker.go:133] RequestWatchProgress feature is not supported by "unix:///var/snap/k8s/common/var/lib/k8s-dqlite/k8s-dqlite.sock" endpoint
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.091910   37236 handler.go:286] Adding GroupVersion apiextensions.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.091943   37236 genericapiserver.go:767] Skipping API apiextensions.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.224392   37236 handler.go:286] Adding GroupVersion  v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.224831   37236 apis.go:106] API group "internal.apiserver.k8s.io" is not enabled, skipping.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.270473   37236 apis.go:106] API group "storagemigration.k8s.io" is not enabled, skipping.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.295366   37236 apis.go:106] API group "resource.k8s.io" is not enabled, skipping.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.326193   37236 handler.go:286] Adding GroupVersion authentication.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.326240   37236 genericapiserver.go:767] Skipping API authentication.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.326257   37236 genericapiserver.go:767] Skipping API authentication.k8s.io/v1alpha1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.327082   37236 handler.go:286] Adding GroupVersion authorization.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.327104   37236 genericapiserver.go:767] Skipping API authorization.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.330351   37236 handler.go:286] Adding GroupVersion autoscaling v2 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.331597   37236 handler.go:286] Adding GroupVersion autoscaling v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.331620   37236 genericapiserver.go:767] Skipping API autoscaling/v2beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.331633   37236 genericapiserver.go:767] Skipping API autoscaling/v2beta2 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.334002   37236 handler.go:286] Adding GroupVersion batch v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.334025   37236 genericapiserver.go:767] Skipping API batch/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.335470   37236 handler.go:286] Adding GroupVersion certificates.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.335493   37236 genericapiserver.go:767] Skipping API certificates.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.335506   37236 genericapiserver.go:767] Skipping API certificates.k8s.io/v1alpha1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.336666   37236 handler.go:286] Adding GroupVersion coordination.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.336688   37236 genericapiserver.go:767] Skipping API coordination.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.336701   37236 genericapiserver.go:767] Skipping API coordination.k8s.io/v1alpha2 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.337751   37236 handler.go:286] Adding GroupVersion discovery.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.337776   37236 genericapiserver.go:767] Skipping API discovery.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.340535   37236 handler.go:286] Adding GroupVersion networking.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.340557   37236 genericapiserver.go:767] Skipping API networking.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.340570   37236 genericapiserver.go:767] Skipping API networking.k8s.io/v1alpha1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.341373   37236 handler.go:286] Adding GroupVersion node.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.341395   37236 genericapiserver.go:767] Skipping API node.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.341409   37236 genericapiserver.go:767] Skipping API node.k8s.io/v1alpha1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.342740   37236 handler.go:286] Adding GroupVersion policy v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.342762   37236 genericapiserver.go:767] Skipping API policy/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.345689   37236 handler.go:286] Adding GroupVersion rbac.authorization.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.345711   37236 genericapiserver.go:767] Skipping API rbac.authorization.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.345726   37236 genericapiserver.go:767] Skipping API rbac.authorization.k8s.io/v1alpha1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.346517   37236 handler.go:286] Adding GroupVersion scheduling.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.346542   37236 genericapiserver.go:767] Skipping API scheduling.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.346555   37236 genericapiserver.go:767] Skipping API scheduling.k8s.io/v1alpha1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.350194   37236 handler.go:286] Adding GroupVersion storage.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.350219   37236 genericapiserver.go:767] Skipping API storage.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.350231   37236 genericapiserver.go:767] Skipping API storage.k8s.io/v1alpha1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.352294   37236 handler.go:286] Adding GroupVersion flowcontrol.apiserver.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.352317   37236 genericapiserver.go:767] Skipping API flowcontrol.apiserver.k8s.io/v1beta3 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.352331   37236 genericapiserver.go:767] Skipping API flowcontrol.apiserver.k8s.io/v1beta2 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.352341   37236 genericapiserver.go:767] Skipping API flowcontrol.apiserver.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.359301   37236 handler.go:286] Adding GroupVersion apps v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.359325   37236 genericapiserver.go:767] Skipping API apps/v1beta2 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.359338   37236 genericapiserver.go:767] Skipping API apps/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.363199   37236 handler.go:286] Adding GroupVersion admissionregistration.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.363221   37236 genericapiserver.go:767] Skipping API admissionregistration.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.363235   37236 genericapiserver.go:767] Skipping API admissionregistration.k8s.io/v1alpha1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.364517   37236 handler.go:286] Adding GroupVersion events.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.364539   37236 genericapiserver.go:767] Skipping API events.k8s.io/v1beta1 because it has no resources.
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: I0516 19:33:17.370346   37236 handler.go:286] Adding GroupVersion apiregistration.k8s.io v1 to ResourceManager
May 16 19:33:17 research21 k8s.kube-apiserver[37236]: W0516 19:33:17.370376   37236 genericapiserver.go:767] Skipping API apiregistration.k8s.io/v1beta1 because it has no resources.
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: W0516 19:33:18.140326   37236 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA' detected.
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: W0516 19:33:18.140370   37236 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_3DES_EDE_CBC_SHA' detected.
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: W0516 19:33:18.140380   37236 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_CBC_SHA' detected.
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: W0516 19:33:18.140391   37236 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_128_GCM_SHA256' detected.
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: W0516 19:33:18.140398   37236 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_CBC_SHA' detected.
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: W0516 19:33:18.140406   37236 secure_serving.go:69] Use of insecure cipher 'TLS_RSA_WITH_AES_256_GCM_SHA384' detected.
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.141502   37236 secure_serving.go:213] Serving securely on [::]:6443
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.142622   37236 dynamic_cafile_content.go:161] "Starting controller" name="request-header::/etc/kubernetes/pki/front-proxy-ca.crt"
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.142690   37236 tlsconfig.go:243] "Starting DynamicServingCertificateController"
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.142623   37236 dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/client-ca.crt"
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.142841   37236 dynamic_serving_content.go:135] "Starting controller" name="serving-cert::/etc/kubernetes/pki/apiserver.crt::/etc/kubernetes/pki/apiserver.key"
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.142973   37236 cluster_authentication_trust_controller.go:462] Starting cluster_authentication_trust_controller controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.142997   37236 shared_informer.go:313] Waiting for caches to sync for cluster_authentication_trust_controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.143023   37236 aggregator.go:169] waiting for initial CRD sync...
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.143031   37236 remote_available_controller.go:411] Starting RemoteAvailability controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.143046   37236 apiservice_controller.go:100] Starting APIServiceRegistrationController
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.143062   37236 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.143171   37236 controller.go:119] Starting legacy_token_tracking_controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.143191   37236 shared_informer.go:313] Waiting for caches to sync for configmaps
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.143229   37236 controller.go:80] Starting OpenAPI V3 AggregationController
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.143568   37236 crdregistration_controller.go:114] Starting crd-autoregister controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.143586   37236 shared_informer.go:313] Waiting for caches to sync for crd-autoregister
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.144214   37236 dynamic_serving_content.go:135] "Starting controller" name="aggregator-proxy-cert::/etc/kubernetes/pki/front-proxy-client.crt::/etc/kubernetes/pki/front-proxy-client.key"
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.148410   37236 customresource_discovery_controller.go:292] Starting DiscoveryController
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.148487   37236 local_available_controller.go:156] Starting LocalAvailability controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.148503   37236 cache.go:32] Waiting for caches to sync for LocalAvailability controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.153003   37236 gc_controller.go:78] Starting apiserver lease garbage collector
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.153082   37236 system_namespaces_controller.go:66] Starting system namespaces controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.153130   37236 controller.go:78] Starting OpenAPI AggregationController
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.153208   37236 apf_controller.go:377] Starting API Priority and Fairness config controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.153291   37236 dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/client-ca.crt"
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.153401   37236 dynamic_cafile_content.go:161] "Starting controller" name="request-header::/etc/kubernetes/pki/front-proxy-ca.crt"
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.143051   37236 cache.go:32] Waiting for caches to sync for RemoteAvailability controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.161065   37236 controller.go:142] Starting OpenAPI controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.161127   37236 controller.go:90] Starting OpenAPI V3 controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.161162   37236 naming_controller.go:294] Starting NamingConditionController
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.161190   37236 establishing_controller.go:81] Starting EstablishingController
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.161215   37236 nonstructuralschema_controller.go:195] Starting NonStructuralSchemaConditionController
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.161238   37236 apiapproval_controller.go:189] Starting KubernetesAPIApprovalPolicyConformantConditionController
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.161260   37236 crd_finalizer.go:269] Starting CRDFinalizer
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.248541   37236 cache.go:39] Caches are synced for LocalAvailability controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.252391   37236 shared_informer.go:320] Caches are synced for cluster_authentication_trust_controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.252442   37236 cache.go:39] Caches are synced for APIServiceRegistrationController controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.253335   37236 apf_controller.go:382] Running API Priority and Fairness config worker
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.253362   37236 apf_controller.go:385] Running API Priority and Fairness periodic rebalancing process
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.253863   37236 cache.go:39] Caches are synced for RemoteAvailability controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.253914   37236 handler_discovery.go:451] Starting ResourceDiscoveryManager
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.255861   37236 shared_informer.go:320] Caches are synced for crd-autoregister
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.255904   37236 aggregator.go:171] initial CRD sync complete...
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.255918   37236 autoregister_controller.go:144] Starting autoregister controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.255928   37236 cache.go:32] Waiting for caches to sync for autoregister controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.255940   37236 cache.go:39] Caches are synced for autoregister controller
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.257330   37236 shared_informer.go:320] Caches are synced for *generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.257361   37236 policy_source.go:240] refreshing policies
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.271315   37236 controller.go:615] quota admission added evaluator for: namespaces
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.327550   37236 controller.go:615] quota admission added evaluator for: leases.coordination.k8s.io
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.335407   37236 shared_informer.go:320] Caches are synced for node_authorizer
May 16 19:33:18 research21 k8s.kube-apiserver[37236]: I0516 19:33:18.343279   37236 shared_informer.go:320] Caches are synced for configmaps
May 16 19:33:19 research21 k8s.kube-apiserver[37236]: I0516 19:33:19.184634   37236 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
May 16 19:33:19 research21 k8s.kube-apiserver[37236]: I0516 19:33:19.194433   37236 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
May 16 19:33:19 research21 k8s.kube-apiserver[37236]: I0516 19:33:19.194481   37236 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
May 16 19:33:20 research21 k8s.kube-apiserver[37236]: I0516 19:33:20.147600   37236 controller.go:615] quota admission added evaluator for: roles.rbac.authorization.k8s.io
May 16 19:33:20 research21 k8s.kube-apiserver[37236]: I0516 19:33:20.220323   37236 controller.go:615] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
May 16 19:33:20 research21 k8s.kube-apiserver[37236]: I0516 19:33:20.378933   37236 alloc.go:330] "allocated clusterIPs" service="default/kubernetes" clusterIPs={"IPv4":"10.152.183.1"}
May 16 19:33:20 research21 k8s.kube-apiserver[37236]: W0516 19:33:20.392911   37236 lease.go:265] Resetting endpoints for master service "kubernetes" to [172.24.188.57]
May 16 19:33:20 research21 k8s.kube-apiserver[37236]: I0516 19:33:20.395029   37236 controller.go:615] quota admission added evaluator for: endpoints
May 16 19:33:20 research21 k8s.kube-apiserver[37236]: I0516 19:33:20.407446   37236 controller.go:615] quota admission added evaluator for: endpointslices.discovery.k8s.io
May 16 19:33:25 research21 k8s.kube-apiserver[37236]: I0516 19:33:25.055046   37236 alloc.go:330] "allocated clusterIPs" service="kube-system/coredns" clusterIPs={"IPv4":"10.152.183.178"}
May 16 19:33:25 research21 k8s.kube-apiserver[37236]: I0516 19:33:25.107191   37236 controller.go:615] quota admission added evaluator for: deployments.apps
May 16 19:33:25 research21 k8s.kube-apiserver[37236]: I0516 19:33:25.543498   37236 controller.go:615] quota admission added evaluator for: serviceaccounts
May 16 19:33:25 research21 k8s.kube-apiserver[37236]: I0516 19:33:25.674469   37236 alloc.go:330] "allocated clusterIPs" service="kube-system/metrics-server" clusterIPs={"IPv4":"10.152.183.156"}
May 16 19:33:25 research21 k8s.kube-apiserver[37236]: I0516 19:33:25.768301   37236 handler.go:286] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
May 16 19:33:25 research21 k8s.kube-apiserver[37236]: W0516 19:33:25.802726   37236 handler_proxy.go:99] no RequestInfo found in the context
May 16 19:33:25 research21 k8s.kube-apiserver[37236]: E0516 19:33:25.805224   37236 controller.go:146] "Unhandled Error" err=<
May 16 19:33:25 research21 k8s.kube-apiserver[37236]:         Error updating APIService "v1beta1.metrics.k8s.io" with err: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
May 16 19:33:25 research21 k8s.kube-apiserver[37236]:         , Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
May 16 19:33:25 research21 k8s.kube-apiserver[37236]:  > logger="UnhandledError"
May 16 19:33:26 research21 k8s.kube-apiserver[37236]: W0516 19:33:26.770507   37236 handler_proxy.go:99] no RequestInfo found in the context
May 16 19:33:26 research21 k8s.kube-apiserver[37236]: E0516 19:33:26.770575   37236 controller.go:113] "Unhandled Error" err="loading OpenAPI spec for \"v1beta1.metrics.k8s.io\" failed with: Error, could not get list of group versions for APIService" logger="UnhandledError"
May 16 19:33:26 research21 k8s.kube-apiserver[37236]: W0516 19:33:26.770637   37236 handler_proxy.go:99] no RequestInfo found in the context
May 16 19:33:26 research21 k8s.kube-apiserver[37236]: E0516 19:33:26.770717   37236 controller.go:102] "Unhandled Error" err=<
May 16 19:33:26 research21 k8s.kube-apiserver[37236]:         loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
May 16 19:33:26 research21 k8s.kube-apiserver[37236]:         , Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
May 16 19:33:26 research21 k8s.kube-apiserver[37236]:  > logger="UnhandledError"
May 16 19:33:26 research21 k8s.kube-apiserver[37236]: I0516 19:33:26.771714   37236 controller.go:126] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
May 16 19:33:26 research21 k8s.kube-apiserver[37236]: I0516 19:33:26.771752   37236 controller.go:109] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
May 16 19:33:27 research21 k8s.kube-apiserver[37236]: I0516 19:33:27.402583   37236 alloc.go:330] "allocated clusterIPs" service="kube-system/ck-storage-rawfile-csi-node" clusterIPs={"IPv4":"10.152.183.57"}
May 16 19:33:27 research21 k8s.kube-apiserver[37236]: I0516 19:33:27.415087   37236 controller.go:615] quota admission added evaluator for: daemonsets.apps
May 16 19:33:27 research21 k8s.kube-apiserver[37236]: I0516 19:33:27.444269   37236 controller.go:615] quota admission added evaluator for: statefulsets.apps
May 16 19:33:28 research21 k8s.kube-apiserver[37236]: I0516 19:33:28.579098   37236 handler.go:286] Adding GroupVersion metallb.io v1beta1 to ResourceManager
May 16 19:33:28 research21 k8s.kube-apiserver[37236]: I0516 19:33:28.631740   37236 handler.go:286] Adding GroupVersion metallb.io v1beta1 to ResourceManager
May 16 19:33:28 research21 k8s.kube-apiserver[37236]: I0516 19:33:28.708772   37236 handler.go:286] Adding GroupVersion metallb.io v1beta1 to ResourceManager
May 16 19:33:28 research21 k8s.kube-apiserver[37236]: I0516 19:33:28.724896   37236 alloc.go:330] "allocated clusterIPs" service="metallb-system/metallb-webhook-service" clusterIPs={"IPv4":"10.152.183.205"}
May 16 19:33:28 research21 k8s.kube-apiserver[37236]: I0516 19:33:28.788592   37236 handler.go:286] Adding GroupVersion metallb.io v1beta1 to ResourceManager
May 16 19:33:28 research21 k8s.kube-apiserver[37236]: I0516 19:33:28.832871   37236 handler.go:286] Adding GroupVersion metallb.io v1beta1 to ResourceManager
May 16 19:33:28 research21 k8s.kube-apiserver[37236]: I0516 19:33:28.874105   37236 handler.go:286] Adding GroupVersion metallb.io v1beta1 to ResourceManager
May 16 19:33:28 research21 k8s.kube-apiserver[37236]: I0516 19:33:28.918223   37236 handler.go:286] Adding GroupVersion metallb.io v1beta1 to ResourceManager
May 16 19:33:28 research21 k8s.kube-apiserver[37236]: I0516 19:33:28.918337   37236 handler.go:286] Adding GroupVersion metallb.io v1beta2 to ResourceManager
May 16 19:33:29 research21 k8s.kube-apiserver[37236]: I0516 19:33:29.906405   37236 alloc.go:330] "allocated clusterIPs" service="kube-system/hubble-peer" clusterIPs={"IPv4":"10.152.183.85"}
May 16 19:33:30 research21 k8s.kube-apiserver[37236]: W0516 19:33:30.854286   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: connection refused
May 16 19:33:30 research21 k8s.kube-apiserver[37236]: W0516 19:33:30.885694   37236 dispatcher.go:217] Failed calling webhook, failing closed l2advertisementvalidationwebhook.metallb.io: failed calling webhook "l2advertisementvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-l2advertisement?timeout=10s": dial tcp 10.152.183.205:443: connect: connection refused
May 16 19:33:30 research21 k8s.kube-apiserver[37236]: W0516 19:33:30.971334   37236 handler_proxy.go:99] no RequestInfo found in the context
May 16 19:33:30 research21 k8s.kube-apiserver[37236]: E0516 19:33:30.971430   37236 controller.go:146] "Unhandled Error" err=<
May 16 19:33:30 research21 k8s.kube-apiserver[37236]:         Error updating APIService "v1beta1.metrics.k8s.io" with err: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
May 16 19:33:30 research21 k8s.kube-apiserver[37236]:         , Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
May 16 19:33:30 research21 k8s.kube-apiserver[37236]:  > logger="UnhandledError"
May 16 19:33:31 research21 k8s.kube-apiserver[37236]: I0516 19:33:31.409136   37236 controller.go:615] quota admission added evaluator for: replicasets.apps
May 16 19:33:31 research21 k8s.kube-apiserver[37236]: I0516 19:33:31.477846   37236 controller.go:615] quota admission added evaluator for: controllerrevisions.apps
May 16 19:33:31 research21 k8s.kube-apiserver[37236]: W0516 19:33:31.976921   37236 handler_proxy.go:99] no RequestInfo found in the context
May 16 19:33:31 research21 k8s.kube-apiserver[37236]: E0516 19:33:31.977006   37236 controller.go:113] "Unhandled Error" err="loading OpenAPI spec for \"v1beta1.metrics.k8s.io\" failed with: Error, could not get list of group versions for APIService" logger="UnhandledError"
May 16 19:33:31 research21 k8s.kube-apiserver[37236]: I0516 19:33:31.979794   37236 controller.go:126] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
May 16 19:33:31 research21 k8s.kube-apiserver[37236]: W0516 19:33:31.984196   37236 handler_proxy.go:99] no RequestInfo found in the context
May 16 19:33:31 research21 k8s.kube-apiserver[37236]: E0516 19:33:31.984314   37236 controller.go:102] "Unhandled Error" err=<
May 16 19:33:31 research21 k8s.kube-apiserver[37236]:         loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
May 16 19:33:31 research21 k8s.kube-apiserver[37236]:         , Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
May 16 19:33:31 research21 k8s.kube-apiserver[37236]:  > logger="UnhandledError"
May 16 19:33:31 research21 k8s.kube-apiserver[37236]: I0516 19:33:31.986186   37236 controller.go:109] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
May 16 19:33:45 research21 k8s.kube-apiserver[37236]: W0516 19:33:45.885645   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: connection refused
May 16 19:33:52 research21 k8s.kube-apiserver[37236]: I0516 19:33:52.920149   37236 handler.go:286] Adding GroupVersion cilium.io v2alpha1 to ResourceManager
May 16 19:33:52 research21 k8s.kube-apiserver[37236]: I0516 19:33:52.988733   37236 handler.go:286] Adding GroupVersion cilium.io v2alpha1 to ResourceManager
May 16 19:33:53 research21 k8s.kube-apiserver[37236]: I0516 19:33:53.087322   37236 handler.go:286] Adding GroupVersion cilium.io v2alpha1 to ResourceManager
May 16 19:33:53 research21 k8s.kube-apiserver[37236]: I0516 19:33:53.097771   37236 handler.go:286] Adding GroupVersion cilium.io v2 to ResourceManager
May 16 19:33:53 research21 k8s.kube-apiserver[37236]: I0516 19:33:53.131859   37236 handler.go:286] Adding GroupVersion cilium.io v2 to ResourceManager
May 16 19:33:53 research21 k8s.kube-apiserver[37236]: I0516 19:33:53.282706   37236 handler.go:286] Adding GroupVersion cilium.io v2 to ResourceManager
May 16 19:33:53 research21 k8s.kube-apiserver[37236]: I0516 19:33:53.314202   37236 handler.go:286] Adding GroupVersion cilium.io v2 to ResourceManager
May 16 19:33:53 research21 k8s.kube-apiserver[37236]: I0516 19:33:53.334707   37236 handler.go:286] Adding GroupVersion cilium.io v2 to ResourceManager
May 16 19:33:53 research21 k8s.kube-apiserver[37236]: I0516 19:33:53.334792   37236 handler.go:286] Adding GroupVersion cilium.io v2alpha1 to ResourceManager
May 16 19:33:53 research21 k8s.kube-apiserver[37236]: I0516 19:33:53.388771   37236 handler.go:286] Adding GroupVersion cilium.io v2alpha1 to ResourceManager
May 16 19:33:54 research21 k8s.kube-apiserver[37236]: I0516 19:33:54.785491   37236 handler.go:286] Adding GroupVersion cilium.io v2 to ResourceManager
May 16 19:33:55 research21 k8s.kube-apiserver[37236]: I0516 19:33:55.383813   37236 handler.go:286] Adding GroupVersion cilium.io v2 to ResourceManager
May 16 19:34:01 research21 k8s.kube-apiserver[37236]: W0516 19:34:01.107821   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: connection refused
May 16 19:34:15 research21 k8s.kube-apiserver[37236]: W0516 19:34:15.981588   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: connection refused
May 16 19:34:25 research21 k8s.kube-apiserver[37236]: W0516 19:34:25.961820   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: connection refused
May 16 19:34:31 research21 k8s.kube-apiserver[37236]: W0516 19:34:31.983625   37236 handler_proxy.go:99] no RequestInfo found in the context
May 16 19:34:31 research21 k8s.kube-apiserver[37236]: E0516 19:34:31.983701   37236 controller.go:113] "Unhandled Error" err="loading OpenAPI spec for \"v1beta1.metrics.k8s.io\" failed with: Error, could not get list of group versions for APIService" logger="UnhandledError"
May 16 19:34:31 research21 k8s.kube-apiserver[37236]: I0516 19:34:31.984836   37236 controller.go:126] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
May 16 19:34:31 research21 k8s.kube-apiserver[37236]: W0516 19:34:31.987080   37236 handler_proxy.go:99] no RequestInfo found in the context
May 16 19:34:31 research21 k8s.kube-apiserver[37236]: E0516 19:34:31.987200   37236 controller.go:102] "Unhandled Error" err=<
May 16 19:34:31 research21 k8s.kube-apiserver[37236]:         loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
May 16 19:34:31 research21 k8s.kube-apiserver[37236]:         , Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
May 16 19:34:31 research21 k8s.kube-apiserver[37236]:  > logger="UnhandledError"
May 16 19:34:31 research21 k8s.kube-apiserver[37236]: I0516 19:34:31.989176   37236 controller.go:109] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
May 16 19:34:35 research21 k8s.kube-apiserver[37236]: W0516 19:34:35.485150   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: connection refused
May 16 19:34:42 research21 k8s.kube-apiserver[37236]: W0516 19:34:42.834409   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: connection refused
May 16 19:34:48 research21 k8s.kube-apiserver[37236]: W0516 19:34:48.398635   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: connection refused
May 16 19:34:54 research21 k8s.kube-apiserver[37236]: W0516 19:34:54.714866   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: connection refused
May 16 19:34:59 research21 k8s.kube-apiserver[37236]: W0516 19:34:59.527017   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: connection refused
May 16 19:35:06 research21 k8s.kube-apiserver[37236]: W0516 19:35:06.134012   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: operation not permitted
May 16 19:35:09 research21 k8s.kube-apiserver[37236]: I0516 19:35:09.755051   37236 controller.go:615] quota admission added evaluator for: ciliumendpoints.cilium.io
May 16 19:35:12 research21 k8s.kube-apiserver[37236]: W0516 19:35:12.939157   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: operation not permitted
May 16 19:35:18 research21 k8s.kube-apiserver[37236]: W0516 19:35:18.531255   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: operation not permitted
May 16 19:35:23 research21 k8s.kube-apiserver[37236]: W0516 19:35:23.717354   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: operation not permitted
May 16 19:35:30 research21 k8s.kube-apiserver[37236]: W0516 19:35:30.073165   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: operation not permitted
May 16 19:35:39 research21 k8s.kube-apiserver[37236]: W0516 19:35:39.025861   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: operation not permitted
May 16 19:35:44 research21 k8s.kube-apiserver[37236]: I0516 19:35:44.671850   37236 controller.go:615] quota admission added evaluator for: csistoragecapacities.storage.k8s.io
May 16 19:35:47 research21 k8s.kube-apiserver[37236]: W0516 19:35:47.721605   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: operation not permitted
May 16 19:35:51 research21 k8s.kube-apiserver[37236]: W0516 19:35:51.838027   37236 cacher.go:171] Terminating all watchers from cacher bgppeers.metallb.io
May 16 19:35:53 research21 k8s.kube-apiserver[37236]: W0516 19:35:53.610434   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: operation not permitted
May 16 19:35:57 research21 k8s.kube-apiserver[37236]: W0516 19:35:57.600698   37236 cacher.go:171] Terminating all watchers from cacher bgppeers.metallb.io
May 16 19:35:58 research21 k8s.kube-apiserver[37236]: W0516 19:35:58.303679   37236 dispatcher.go:217] Failed calling webhook, failing closed ipaddresspoolvalidationwebhook.metallb.io: failed calling webhook "ipaddresspoolvalidationwebhook.metallb.io": failed to call webhook: Post "https://metallb-webhook-service.metallb-system.svc:443/validate-metallb-io-v1beta1-ipaddresspool?timeout=10s": dial tcp 10.152.183.205:443: connect: operation not permitted
May 16 19:36:02 research21 k8s.kube-apiserver[37236]: W0516 19:36:02.686625   37236 cacher.go:171] Terminating all watchers from cacher bgppeers.metallb.io
May 16 19:36:03 research21 k8s.kube-apiserver[37236]: I0516 19:36:03.405001   37236 controller.go:615] quota admission added evaluator for: ipaddresspools.metallb.io
May 16 19:36:03 research21 k8s.kube-apiserver[37236]: I0516 19:36:03.445194   37236 controller.go:615] quota admission added evaluator for: l2advertisements.metallb.io
May 16 19:36:06 research21 k8s.kube-apiserver[37236]: E0516 19:36:06.787214   37236 remote_available_controller.go:448] "Unhandled Error" err="v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.152.183.156:443/apis/metrics.k8s.io/v1beta1: Get \"https://10.152.183.156:443/apis/metrics.k8s.io/v1beta1\": dial tcp 10.152.183.156:443: connect: operation not permitted" logger="UnhandledError"
May 16 19:36:06 research21 k8s.kube-apiserver[37236]: W0516 19:36:06.787540   37236 handler_proxy.go:99] no RequestInfo found in the context
May 16 19:36:06 research21 k8s.kube-apiserver[37236]: E0516 19:36:06.787627   37236 controller.go:146] "Unhandled Error" err=<
May 16 19:36:06 research21 k8s.kube-apiserver[37236]:         Error updating APIService "v1beta1.metrics.k8s.io" with err: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: service unavailable
May 16 19:36:06 research21 k8s.kube-apiserver[37236]:         , Header: map[Content-Type:[text/plain; charset=utf-8] X-Content-Type-Options:[nosniff]]
May 16 19:36:06 research21 k8s.kube-apiserver[37236]:  > logger="UnhandledError"
May 16 19:36:06 research21 k8s.kube-apiserver[37236]: I0516 19:36:06.831075   37236 handler.go:286] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
May 16 19:36:58 research21 k8s.kube-apiserver[37236]: I0516 19:36:58.350750   37236 alloc.go:330] "allocated clusterIPs" service="controller-sunbeam-controller/controller-service" clusterIPs={"IPv4":"10.152.183.155"}
May 16 19:38:11 research21 k8s.kube-apiserver[37236]: I0516 19:38:11.089575   37236 controller.go:615] quota admission added evaluator for: servicel2statuses.metallb.io
May 16 19:38:13 research21 k8s.kube-apiserver[37236]: I0516 19:38:13.138493   37236 alloc.go:330] "allocated clusterIPs" service="controller-sunbeam-controller/modeloperator" clusterIPs={"IPv4":"10.152.183.228"}
May 16 19:39:21 research21 k8s.kube-apiserver[37236]: W0516 19:39:21.528376   37236 cacher.go:171] Terminating all watchers from cacher bgppeers.metallb.io
May 16 19:39:37 research21 k8s.kube-apiserver[37236]: W0516 19:39:37.590491   37236 cacher.go:171] Terminating all watchers from cacher bgppeers.metallb.io
May 16 19:39:47 research21 k8s.kube-apiserver[37236]: W0516 19:39:47.876694   37236 cacher.go:171] Terminating all watchers from cacher bgppeers.metallb.io
May 16 19:39:53 research21 k8s.kube-apiserver[37236]: I0516 19:39:53.980127   37236 alloc.go:330] "allocated clusterIPs" service="openstack/modeloperator" clusterIPs={"IPv4":"10.152.183.164"}
May 16 19:40:04 research21 k8s.kube-apiserver[37236]: I0516 19:40:04.373834   37236 alloc.go:330] "allocated clusterIPs" service="openstack/ovn-relay" clusterIPs={"IPv4":"10.152.183.71"}
May 16 19:40:08 research21 k8s.kube-apiserver[37236]: I0516 19:40:08.186774   37236 alloc.go:330] "allocated clusterIPs" service="openstack/rabbitmq" clusterIPs={"IPv4":"10.152.183.232"}
May 16 19:40:10 research21 k8s.kube-apiserver[37236]: I0516 19:40:10.562049   37236 alloc.go:330] "allocated clusterIPs" service="openstack/certificate-authority" clusterIPs={"IPv4":"10.152.183.100"}
May 16 19:40:21 research21 k8s.kube-apiserver[37236]: I0516 19:40:21.181859   37236 alloc.go:330] "allocated clusterIPs" service="openstack/traefik" clusterIPs={"IPv4":"10.152.183.44"}
May 16 19:40:25 research21 k8s.kube-apiserver[37236]: I0516 19:40:25.425956   37236 alloc.go:330] "allocated clusterIPs" service="openstack/traefik-public" clusterIPs={"IPv4":"10.152.183.20"}
May 16 19:40:26 research21 k8s.kube-apiserver[37236]: I0516 19:40:26.613746   37236 alloc.go:330] "allocated clusterIPs" service="openstack/ovn-central" clusterIPs={"IPv4":"10.152.183.243"}
May 16 19:40:31 research21 k8s.kube-apiserver[37236]: I0516 19:40:31.560104   37236 alloc.go:330] "allocated clusterIPs" service="openstack/mysql" clusterIPs={"IPv4":"10.152.183.152"}
May 16 19:41:02 research21 k8s.kube-apiserver[37236]: I0516 19:41:02.564533   37236 alloc.go:330] "allocated clusterIPs" service="openstack/rabbitmq-lb" clusterIPs={"IPv4":"10.152.183.150"}
May 16 19:41:06 research21 k8s.kube-apiserver[37236]: I0516 19:41:06.057381   37236 alloc.go:330] "allocated clusterIPs" service="openstack/ovn-relay-lb" clusterIPs={"IPv4":"10.152.183.244"}
May 16 19:41:48 research21 k8s.kube-apiserver[37236]: I0516 19:41:48.995961   37236 alloc.go:330] "allocated clusterIPs" service="openstack/neutron" clusterIPs={"IPv4":"10.152.183.148"}
May 16 19:41:51 research21 k8s.kube-apiserver[37236]: I0516 19:41:51.764946   37236 alloc.go:330] "allocated clusterIPs" service="openstack/nova-mysql-router" clusterIPs={"IPv4":"10.152.183.197"}
May 16 19:41:54 research21 k8s.kube-apiserver[37236]: I0516 19:41:54.531438   37236 alloc.go:330] "allocated clusterIPs" service="openstack/neutron-mysql-router" clusterIPs={"IPv4":"10.152.183.49"}
May 16 19:41:56 research21 k8s.kube-apiserver[37236]: I0516 19:41:56.847956   37236 alloc.go:330] "allocated clusterIPs" service="openstack/nova-api-mysql-router" clusterIPs={"IPv4":"10.152.183.145"}
May 16 19:42:00 research21 k8s.kube-apiserver[37236]: I0516 19:42:00.868499   37236 alloc.go:330] "allocated clusterIPs" service="openstack/cinder" clusterIPs={"IPv4":"10.152.183.210"}
May 16 19:42:15 research21 k8s.kube-apiserver[37236]: I0516 19:42:15.294725   37236 alloc.go:330] "allocated clusterIPs" service="openstack/glance" clusterIPs={"IPv4":"10.152.183.229"}
May 16 19:42:16 research21 k8s.kube-apiserver[37236]: I0516 19:42:16.375342   37236 alloc.go:330] "allocated clusterIPs" service="openstack/glance-mysql-router" clusterIPs={"IPv4":"10.152.183.233"}
May 16 19:42:17 research21 k8s.kube-apiserver[37236]: I0516 19:42:17.969208   37236 alloc.go:330] "allocated clusterIPs" service="openstack/nova-cell-mysql-router" clusterIPs={"IPv4":"10.152.183.151"}
May 16 19:42:27 research21 k8s.kube-apiserver[37236]: I0516 19:42:27.452563   37236 alloc.go:330] "allocated clusterIPs" service="openstack/cinder-mysql-router" clusterIPs={"IPv4":"10.152.183.58"}
May 16 19:42:32 research21 k8s.kube-apiserver[37236]: I0516 19:42:32.237061   37236 alloc.go:330] "allocated clusterIPs" service="openstack/keystone-mysql-router" clusterIPs={"IPv4":"10.152.183.74"}
May 16 19:42:34 research21 k8s.kube-apiserver[37236]: I0516 19:42:34.196851   37236 alloc.go:330] "allocated clusterIPs" service="openstack/nova" clusterIPs={"IPv4":"10.152.183.234"}
May 16 19:42:36 research21 k8s.kube-apiserver[37236]: I0516 19:42:36.611322   37236 alloc.go:330] "allocated clusterIPs" service="openstack/horizon-mysql-router" clusterIPs={"IPv4":"10.152.183.143"}
May 16 19:42:43 research21 k8s.kube-apiserver[37236]: I0516 19:42:43.775146   37236 alloc.go:330] "allocated clusterIPs" service="openstack/placement" clusterIPs={"IPv4":"10.152.183.137"}
May 16 19:42:45 research21 k8s.kube-apiserver[37236]: I0516 19:42:45.850995   37236 alloc.go:330] "allocated clusterIPs" service="openstack/placement-mysql-router" clusterIPs={"IPv4":"10.152.183.173"}
May 16 19:42:56 research21 k8s.kube-apiserver[37236]: I0516 19:42:56.437771   37236 alloc.go:330] "allocated clusterIPs" service="openstack/keystone" clusterIPs={"IPv4":"10.152.183.132"}
May 16 19:43:03 research21 k8s.kube-apiserver[37236]: I0516 19:43:03.776716   37236 alloc.go:330] "allocated clusterIPs" service="openstack/horizon" clusterIPs={"IPv4":"10.152.183.142"}
May 16 19:48:19 research21 k8s.kube-apiserver[37236]: W0516 19:48:19.713507   37236 controller.go:139] slow openapi aggregation of "ciliumnetworkpolicies.cilium.io": 1.136252641s
May 16 19:59:53 research21 k8s.kube-apiserver[37236]: I0516 19:59:53.048760   37236 alloc.go:330] "allocated clusterIPs" service="openstack/traefik-public-lb" clusterIPs={"IPv4":"10.152.183.70"}
May 16 19:59:53 research21 k8s.kube-apiserver[37236]: I0516 19:59:53.538765   37236 alloc.go:330] "allocated clusterIPs" service="openstack/traefik-lb" clusterIPs={"IPv4":"10.152.183.73"}
May 16 20:09:44 research21 k8s.kube-apiserver[37236]: I0516 20:09:44.808748   37236 alloc.go:330] "allocated clusterIPs" service="openstack/mysql-primary" clusterIPs={"IPv4":"10.152.183.112"}
May 16 20:09:45 research21 k8s.kube-apiserver[37236]: I0516 20:09:45.720740   37236 alloc.go:330] "allocated clusterIPs" service="openstack/mysql-replicas" clusterIPs={"IPv4":"10.152.183.108"}
May 16 20:10:37 research21 k8s.kube-apiserver[37236]: I0516 20:10:37.085304   37236 alloc.go:330] "allocated clusterIPs" service="openstack/placement-mysql-router-service" clusterIPs={"IPv4":"10.152.183.59"}
May 16 20:12:39 research21 k8s.kube-apiserver[37236]: I0516 20:12:39.070353   37236 alloc.go:330] "allocated clusterIPs" service="openstack/glance-mysql-router-service" clusterIPs={"IPv4":"10.152.183.214"}
May 16 20:14:50 research21 k8s.kube-apiserver[37236]: I0516 20:14:50.044314   37236 alloc.go:330] "allocated clusterIPs" service="openstack/neutron-mysql-router-service" clusterIPs={"IPv4":"10.152.183.235"}
May 16 20:17:18 research21 k8s.kube-apiserver[37236]: I0516 20:17:18.295420   37236 alloc.go:330] "allocated clusterIPs" service="openstack/nova-api-mysql-router-service" clusterIPs={"IPv4":"10.152.183.211"}
May 16 20:18:48 research21 k8s.kube-apiserver[37236]: I0516 20:18:48.602048   37236 alloc.go:330] "allocated clusterIPs" service="openstack/keystone-mysql-router-service" clusterIPs={"IPv4":"10.152.183.206"}
May 16 20:20:43 research21 k8s.kube-apiserver[37236]: I0516 20:20:43.635995   37236 alloc.go:330] "allocated clusterIPs" service="openstack/nova-mysql-router-service" clusterIPs={"IPv4":"10.152.183.79"}
May 16 20:23:02 research21 k8s.kube-apiserver[37236]: I0516 20:23:02.945175   37236 alloc.go:330] "allocated clusterIPs" service="openstack/nova-cell-mysql-router-service" clusterIPs={"IPv4":"10.152.183.222"}
May 16 20:25:51 research21 k8s.kube-apiserver[37236]: I0516 20:25:51.651958   37236 alloc.go:330] "allocated clusterIPs" service="openstack/cinder-mysql-router-service" clusterIPs={"IPv4":"10.152.183.114"}
May 16 20:30:59 research21 k8s.kube-apiserver[37236]: I0516 20:30:59.446186   37236 alloc.go:330] "allocated clusterIPs" service="openstack/horizon-mysql-router-service" clusterIPs={"IPv4":"10.152.183.36"}
